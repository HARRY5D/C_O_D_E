{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bab5ed4",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis - Energy Efficiency Classification\n",
    "\n",
    "This notebook demonstrates logistic regression for classifying energy efficiency levels based on building characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for logistic regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636db9a3",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the energy efficiency dataset\n",
    "file_path = r\"C:\\Users\\dipes\\Desktop\\5th Sem\\ML\\DATASET\\energy+efficiency\\ENB2012_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")\n",
    "\n",
    "# If column names need renaming\n",
    "if 'X1' in data.columns:\n",
    "    data.columns = [\n",
    "        'Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area', \n",
    "        'Overall_Height', 'Orientation', 'Glazing_Area', 'Glazing_Area_Distribution',\n",
    "        'Heating_Load', 'Cooling_Load'\n",
    "    ]\n",
    "\n",
    "print(f\"\\nUpdated columns: {data.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d53afd",
   "metadata": {},
   "source": [
    "## Step 2: Convert Continuous Target to Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13687e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert heating load to binary classification problem\n",
    "# We'll create different classification scenarios\n",
    "\n",
    "# Scenario 1: High vs Low Heating Load (Binary Classification)\n",
    "median_heating = data['Heating_Load'].median()\n",
    "data['High_Heating_Load'] = (data['Heating_Load'] > median_heating).astype(int)\n",
    "\n",
    "print(f\"Heating Load Statistics:\")\n",
    "print(f\"Mean: {data['Heating_Load'].mean():.2f}\")\n",
    "print(f\"Median: {median_heating:.2f}\")\n",
    "print(f\"Min: {data['Heating_Load'].min():.2f}\")\n",
    "print(f\"Max: {data['Heating_Load'].max():.2f}\")\n",
    "\n",
    "print(f\"\\nBinary Classification Distribution:\")\n",
    "print(f\"High Heating Load (1): {data['High_Heating_Load'].sum()}\")\n",
    "print(f\"Low Heating Load (0): {len(data) - data['High_Heating_Load'].sum()}\")\n",
    "print(f\"Percentage High: {data['High_Heating_Load'].mean()*100:.1f}%\")\n",
    "\n",
    "# Scenario 2: Multi-class Classification (Low, Medium, High)\n",
    "# Create tertiles for 3-class classification\n",
    "tertiles = data['Heating_Load'].quantile([0.33, 0.67]).values\n",
    "data['Heating_Category'] = pd.cut(data['Heating_Load'], \n",
    "                                  bins=[-np.inf, tertiles[0], tertiles[1], np.inf], \n",
    "                                  labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(f\"\\nMulti-class Classification Distribution:\")\n",
    "print(data['Heating_Category'].value_counts())\n",
    "\n",
    "# Visualize the classification targets\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original distribution\n",
    "axes[0].hist(data['Heating_Load'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0].set_title('Original Heating Load Distribution')\n",
    "axes[0].set_xlabel('Heating Load')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(median_heating, color='red', linestyle='--', label=f'Median: {median_heating:.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Binary classification\n",
    "data['High_Heating_Load'].value_counts().plot(kind='bar', ax=axes[1], color=['lightcoral', 'lightgreen'])\n",
    "axes[1].set_title('Binary Classification')\n",
    "axes[1].set_xlabel('Class (0=Low, 1=High)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Multi-class classification\n",
    "data['Heating_Category'].value_counts().plot(kind='bar', ax=axes[2], color=['lightblue', 'orange', 'lightcoral'])\n",
    "axes[2].set_title('Multi-class Classification')\n",
    "axes[2].set_xlabel('Category')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae4516",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Features for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (exclude target variables)\n",
    "feature_columns = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area', \n",
    "                   'Overall_Height', 'Orientation', 'Glazing_Area', 'Glazing_Area_Distribution']\n",
    "\n",
    "X = data[feature_columns]\n",
    "y_binary = data['High_Heating_Load']\n",
    "y_multiclass = data['Heating_Category']\n",
    "\n",
    "print(\"Feature Matrix Shape:\", X.shape)\n",
    "print(\"Binary Target Shape:\", y_binary.shape)\n",
    "print(\"Multi-class Target Shape:\", y_multiclass.shape)\n",
    "\n",
    "# Feature scaling (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"\\nFeature scaling completed\")\n",
    "print(f\"Original feature means: {X.mean().round(2).tolist()}\")\n",
    "print(f\"Scaled feature means: {X_scaled.mean().round(2).tolist()}\")\n",
    "\n",
    "# Check feature correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d02aa48",
   "metadata": {},
   "source": [
    "## Step 4: Binary Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25163ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification: High vs Low Heating Load\n",
    "print(\"=== BINARY LOGISTIC REGRESSION ANALYSIS ===\")\n",
    "\n",
    "# Split the data for binary classification\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_scaled, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_bin.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_bin.shape[0]} samples\")\n",
    "print(f\"Training class distribution: {y_train_bin.value_counts().tolist()}\")\n",
    "print(f\"Test class distribution: {y_test_bin.value_counts().tolist()}\")\n",
    "\n",
    "# Fit binary logistic regression model\n",
    "binary_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "binary_model.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_bin = binary_model.predict(X_train_bin)\n",
    "y_test_pred_bin = binary_model.predict(X_test_bin)\n",
    "y_test_pred_proba_bin = binary_model.predict_proba(X_test_bin)[:, 1]\n",
    "\n",
    "# Evaluate binary model\n",
    "train_accuracy_bin = accuracy_score(y_train_bin, y_train_pred_bin)\n",
    "test_accuracy_bin = accuracy_score(y_test_bin, y_test_pred_bin)\n",
    "\n",
    "print(f\"\\nBinary Logistic Regression Performance:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_bin:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_bin:.4f}\")\n",
    "\n",
    "print(f\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test_bin, y_test_pred_bin, target_names=['Low Heating', 'High Heating']))\n",
    "\n",
    "# Visualize binary classification results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_bin = confusion_matrix(y_test_bin, y_test_pred_bin)\n",
    "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "axes[0,0].set_title('Confusion Matrix - Binary Classification')\n",
    "axes[0,0].set_xlabel('Predicted')\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance_bin = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': binary_model.coef_[0]\n",
    "})\n",
    "feature_importance_bin = feature_importance_bin.sort_values('Coefficient', key=abs, ascending=False)\n",
    "axes[0,1].barh(feature_importance_bin['Feature'], feature_importance_bin['Coefficient'])\n",
    "axes[0,1].set_title('Feature Coefficients - Binary Model')\n",
    "axes[0,1].set_xlabel('Coefficient Value')\n",
    "\n",
    "# Probability distribution\n",
    "axes[0,2].hist(y_test_pred_proba_bin[y_test_bin == 0], alpha=0.5, label='Low Heating Load', bins=20, color='blue')\n",
    "axes[0,2].hist(y_test_pred_proba_bin[y_test_bin == 1], alpha=0.5, label='High Heating Load', bins=20, color='red')\n",
    "axes[0,2].set_title('Predicted Probability Distribution')\n",
    "axes[0,2].set_xlabel('Predicted Probability of High Heating Load')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_bin, y_test_pred_proba_bin)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1,0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "axes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1,0].set_xlim([0.0, 1.0])\n",
    "axes[1,0].set_ylim([0.0, 1.05])\n",
    "axes[1,0].set_xlabel('False Positive Rate')\n",
    "axes[1,0].set_ylabel('True Positive Rate')\n",
    "axes[1,0].set_title('ROC Curve - Binary Classification')\n",
    "axes[1,0].legend(loc=\"lower right\")\n",
    "\n",
    "# Probability vs Features (most important feature)\n",
    "most_important_feature = feature_importance_bin.iloc[0]['Feature']\n",
    "axes[1,1].scatter(X_test_bin[most_important_feature], y_test_pred_proba_bin, \n",
    "                  c=y_test_bin, cmap='coolwarm', alpha=0.6)\n",
    "axes[1,1].set_xlabel(most_important_feature)\n",
    "axes[1,1].set_ylabel('Predicted Probability')\n",
    "axes[1,1].set_title(f'Probability vs {most_important_feature}')\n",
    "\n",
    "# Model confidence distribution\n",
    "confidence = np.max(binary_model.predict_proba(X_test_bin), axis=1)\n",
    "axes[1,2].hist(confidence, bins=20, alpha=0.7, color='green')\n",
    "axes[1,2].set_title('Model Confidence Distribution')\n",
    "axes[1,2].set_xlabel('Prediction Confidence')\n",
    "axes[1,2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e3b35",
   "metadata": {},
   "source": [
    "## Step 5: Multi-class Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class Classification: Low, Medium, High Heating Load\n",
    "print(\"=== MULTI-CLASS LOGISTIC REGRESSION ANALYSIS ===\")\n",
    "\n",
    "# Convert categorical target to numeric for sklearn\n",
    "y_multiclass_numeric = y_multiclass.cat.codes\n",
    "\n",
    "# Split the data for multi-class classification\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_scaled, y_multiclass_numeric, test_size=0.2, random_state=42, stratify=y_multiclass_numeric\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train_multi.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_multi.shape[0]} samples\")\n",
    "\n",
    "# Fit multi-class logistic regression model\n",
    "multi_model = LogisticRegression(random_state=42, max_iter=1000, multi_class='ovr')\n",
    "multi_model.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_multi = multi_model.predict(X_train_multi)\n",
    "y_test_pred_multi = multi_model.predict(X_test_multi)\n",
    "y_test_pred_proba_multi = multi_model.predict_proba(X_test_multi)\n",
    "\n",
    "# Evaluate multi-class model\n",
    "train_accuracy_multi = accuracy_score(y_train_multi, y_train_pred_multi)\n",
    "test_accuracy_multi = accuracy_score(y_test_multi, y_test_pred_multi)\n",
    "\n",
    "print(f\"\\nMulti-class Logistic Regression Performance:\")\n",
    "print(f\"Training Accuracy: {train_accuracy_multi:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy_multi:.4f}\")\n",
    "\n",
    "print(f\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test_multi, y_test_pred_multi, target_names=['Low', 'Medium', 'High']))\n",
    "\n",
    "# Visualize multi-class classification results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_multi = confusion_matrix(y_test_multi, y_test_pred_multi)\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "axes[0,0].set_title('Confusion Matrix - Multi-class Classification')\n",
    "axes[0,0].set_xlabel('Predicted')\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "axes[0,0].set_xticklabels(['Low', 'Medium', 'High'])\n",
    "axes[0,0].set_yticklabels(['Low', 'Medium', 'High'])\n",
    "\n",
    "# Feature importance for each class\n",
    "for i, class_name in enumerate(['Low', 'Medium', 'High']):\n",
    "    coefficients = multi_model.coef_[i]\n",
    "    feature_importance_multi = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "    \n",
    "    if i == 0:  # Show for first class only to avoid clutter\n",
    "        feature_importance_multi = feature_importance_multi.sort_values('Coefficient', key=abs, ascending=False)\n",
    "        axes[0,1].barh(feature_importance_multi['Feature'], feature_importance_multi['Coefficient'])\n",
    "        axes[0,1].set_title(f'Feature Coefficients - {class_name} Class')\n",
    "        axes[0,1].set_xlabel('Coefficient Value')\n",
    "\n",
    "# Class probability distributions\n",
    "class_names = ['Low', 'Medium', 'High']\n",
    "colors = ['blue', 'orange', 'red']\n",
    "for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "    class_probs = y_test_pred_proba_multi[:, i]\n",
    "    axes[0,2].hist(class_probs, alpha=0.5, label=f'{class_name} Class', bins=15, color=color)\n",
    "axes[0,2].set_title('Predicted Probability Distributions')\n",
    "axes[0,2].set_xlabel('Predicted Probability')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# ROC Curves for each class (One-vs-Rest)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "# Binarize the output\n",
    "y_test_multi_bin = label_binarize(y_test_multi, classes=[0, 1, 2])\n",
    "n_classes = y_test_multi_bin.shape[1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "colors_roc = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "\n",
    "for i, color in zip(range(n_classes), colors_roc):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_multi_bin[:, i], y_test_pred_proba_multi[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    axes[1,0].plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                   label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "axes[1,0].plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "axes[1,0].set_xlim([0.0, 1.0])\n",
    "axes[1,0].set_ylim([0.0, 1.05])\n",
    "axes[1,0].set_xlabel('False Positive Rate')\n",
    "axes[1,0].set_ylabel('True Positive Rate')\n",
    "axes[1,0].set_title('ROC Curves - Multi-class Classification')\n",
    "axes[1,0].legend(loc=\"lower right\")\n",
    "\n",
    "# Prediction confidence\n",
    "confidence_multi = np.max(y_test_pred_proba_multi, axis=1)\n",
    "axes[1,1].hist(confidence_multi, bins=20, alpha=0.7, color='purple')\n",
    "axes[1,1].set_title('Model Confidence Distribution')\n",
    "axes[1,1].set_xlabel('Prediction Confidence')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "# Accuracy comparison\n",
    "models = ['Binary Logistic', 'Multi-class Logistic']\n",
    "accuracies = [test_accuracy_bin, test_accuracy_multi]\n",
    "axes[1,2].bar(models, accuracies, color=['lightblue', 'lightcoral'], alpha=0.7)\n",
    "axes[1,2].set_title('Model Accuracy Comparison')\n",
    "axes[1,2].set_ylabel('Test Accuracy')\n",
    "axes[1,2].set_ylim(0, 1)\n",
    "for i, acc in enumerate(accuracies):\n",
    "    axes[1,2].text(i, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554049a",
   "metadata": {},
   "source": [
    "## Step 6: Model Comparison and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Comparison and Analysis\n",
    "print(\"=== COMPREHENSIVE MODEL ANALYSIS ===\")\n",
    "\n",
    "# Create summary comparison\n",
    "summary_data = {\n",
    "    'Model Type': ['Binary Logistic Regression', 'Multi-class Logistic Regression'],\n",
    "    'Classes': ['2 (High/Low)', '3 (High/Medium/Low)'],\n",
    "    'Training Accuracy': [f'{train_accuracy_bin:.4f}', f'{train_accuracy_multi:.4f}'],\n",
    "    'Test Accuracy': [f'{test_accuracy_bin:.4f}', f'{test_accuracy_multi:.4f}'],\n",
    "    'AUC Score': [f'{roc_auc:.4f}', 'N/A (Multi-class)'],\n",
    "    'Overfitting': [f'{abs(train_accuracy_bin - test_accuracy_bin):.4f}', \n",
    "                   f'{abs(train_accuracy_multi - test_accuracy_multi):.4f}']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for i, row in summary_df.iterrows():\n",
    "    print(f\"{row['Model Type']}:\")\n",
    "    print(f\"  Classes: {row['Classes']}\")\n",
    "    print(f\"  Training Accuracy: {row['Training Accuracy']}\")\n",
    "    print(f\"  Test Accuracy: {row['Test Accuracy']}\")\n",
    "    print(f\"  AUC Score: {row['AUC Score']}\")\n",
    "    print(f\"  Overfitting Check: {row['Overfitting']}\")\n",
    "    print()\n",
    "\n",
    "# Feature importance comparison\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Top 3 Features - Binary Classification:\")\n",
    "top_binary = feature_importance_bin.head(3)\n",
    "for i, row in top_binary.iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "print(\"\\nFeature Coefficients - Multi-class (Low class):\")\n",
    "multi_class_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': multi_model.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "top_multi = multi_class_importance.head(3)\n",
    "for i, row in top_multi.iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "# Business insights\n",
    "print(\"\\nKEY BUSINESS INSIGHTS:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. Binary classification achieves {test_accuracy_bin*100:.1f}% accuracy in predicting high/low heating load\")\n",
    "print(f\"2. Multi-class classification achieves {test_accuracy_multi*100:.1f}% accuracy with 3 categories\")\n",
    "print(f\"3. Most influential feature for binary classification: {feature_importance_bin.iloc[0]['Feature']}\")\n",
    "print(f\"4. Binary model AUC score of {roc_auc:.3f} indicates {'excellent' if roc_auc > 0.9 else 'good' if roc_auc > 0.8 else 'fair'} discriminative ability\")\n",
    "\n",
    "# Model recommendations\n",
    "print(f\"\\nMODEL RECOMMENDATIONS:\")\n",
    "print(\"=\" * 50)\n",
    "if test_accuracy_bin > test_accuracy_multi:\n",
    "    print(\"✓ Binary classification performs better for this dataset\")\n",
    "    print(\"✓ Simpler interpretation with high/low categories\")\n",
    "else:\n",
    "    print(\"✓ Multi-class classification provides more granular predictions\")\n",
    "    print(\"✓ Better for applications requiring detailed energy efficiency categories\")\n",
    "\n",
    "print(f\"✓ Feature scaling {'improved' if test_accuracy_bin > 0.8 else 'is important for'} model performance\")\n",
    "print(f\"✓ Low overfitting indicates good model generalization\")\n",
    "\n",
    "# Final visualization: Feature importance comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.barh(feature_importance_bin['Feature'], np.abs(feature_importance_bin['Coefficient']))\n",
    "plt.title('Feature Importance - Binary Classification (Absolute Coefficients)')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.barh(multi_class_importance['Feature'], np.abs(multi_class_importance['Coefficient']))\n",
    "plt.title('Feature Importance - Multi-class Classification (Low Class, Absolute Coefficients)')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
