{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b544d2",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction using Decision Tree & Random Forest\n",
    "\n",
    "## Problem Definition\n",
    "In a telecom company, predicting whether a customer will churn based on historical data (e.g., call minutes, internet usage, billing issues, and support interactions) is essential. This practical involves using Decision Tree and Random Forest algorithms to build interpretable and accurate models for churn prediction.\n",
    "\n",
    "**CHAROTAR UNIVERSITY OF SCIENCE AND TECHNOLOGY (CHARUSAT)**\n",
    "\n",
    "**FACULTY OF TECHNOLOGY AND ENGINEERING (FTE)**\n",
    "\n",
    "**DEVANG PATEL INSTITUTE OF ADVANCE TECHNOLOGY AND RESEARCH (DEPSTAR)**\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives:\n",
    "1. Load and explore the customer churn dataset\n",
    "2. Preprocess data: encode categorical variables, handle missing values\n",
    "3. Train Decision Tree and Random Forest classifiers\n",
    "4. Compare model performance and analyze feature importance\n",
    "5. Address overfitting via cross-validation and hyperparameter tuning\n",
    "6. Provide business insights for retention strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf47cb7",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab166e",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dc200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(r'd:\\5th Sem\\ML\\DATASET\\churn\\WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file not found. Please check the path.\")\n",
    "    # For demonstration, create a sample dataset if file not found\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    df = pd.DataFrame({\n",
    "        'customerID': [f'ID_{i}' for i in range(n_samples)],\n",
    "        'tenure': np.random.randint(1, 72, n_samples),\n",
    "        'MonthlyCharges': np.random.normal(65, 30, n_samples),\n",
    "        'TotalCharges': np.random.normal(2300, 2000, n_samples),\n",
    "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples),\n",
    "        'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples),\n",
    "        'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'Churn': np.random.choice(['Yes', 'No'], n_samples, p=[0.3, 0.7])\n",
    "    })\n",
    "    print(\"Sample dataset created for demonstration.\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display data types and info\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322449be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check target variable distribution\n",
    "print(\"\\nChurn Distribution:\")\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "print(churn_counts)\n",
    "print(f\"\\nChurn Rate: {churn_counts['Yes'] / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c2782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize churn distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df['Churn'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['Churn'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightcoral'])\n",
    "plt.title('Churn Distribution (%)')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a040a",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    print(f\"\\nTotal missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by filling with median for numerical columns\n",
    "# First, let's identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Remove customerID if it exists (not useful for prediction)\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    categorical_cols.remove('customerID')\n",
    "    print(\"\\nRemoved customerID column\")\n",
    "\n",
    "# Handle potential string values in numerical columns (like TotalCharges)\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        # Convert to numeric, coercing errors to NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # Fill missing values with median\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            median_value = df[col].median()\n",
    "            df[col].fillna(median_value, inplace=True)\n",
    "            print(f\"Filled {col} missing values with median: {median_value:.2f}\")\n",
    "\n",
    "print(\"\\nData preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Removed {duplicates} duplicate rows\")\n",
    "    print(f\"New dataset shape: {df.shape}\")\n",
    "\n",
    "# Final check for missing values\n",
    "print(f\"\\nFinal missing values check: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e8810",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe for encoding\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Initialize label encoders dictionary\n",
    "label_encoders = {}\n",
    "\n",
    "# Update categorical columns list (excluding target variable)\n",
    "categorical_cols = df_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')  # We'll handle target separately\n",
    "\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Encode categorical variables using Label Encoder\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {list(le.classes_)}\")\n",
    "\n",
    "# Encode target variable (Churn)\n",
    "target_encoder = LabelEncoder()\n",
    "df_encoded['Churn'] = target_encoder.fit_transform(df_encoded['Churn'])\n",
    "print(f\"\\nTarget variable encoding: {dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ab025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the encoded dataset\n",
    "print(\"Encoded dataset (first 5 rows):\")\n",
    "display(df_encoded.head())\n",
    "\n",
    "print(f\"\\nEncoded dataset shape: {df_encoded.shape}\")\n",
    "print(f\"Data types after encoding:\")\n",
    "print(df_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612e369",
   "metadata": {},
   "source": [
    "## 5. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain the same proportion of classes in train and test\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set churn distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nTesting set churn distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e2550",
   "metadata": {},
   "source": [
    "## 6. Train Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=5,  # Limit depth to prevent overfitting for visualization\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_train_pred = dt_classifier.predict(X_train)\n",
    "dt_test_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classifier trained successfully!\")\n",
    "print(f\"Tree depth: {dt_classifier.get_depth()}\")\n",
    "print(f\"Number of leaves: {dt_classifier.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68c0fa",
   "metadata": {},
   "source": [
    "## 7. Visualize Decision Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt_classifier,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['No Churn', 'Churn'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Decision Tree Structure for Customer Churn Prediction', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Decision Tree\n",
    "dt_feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': dt_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Decision Tree Feature Importance:\")\n",
    "display(dt_feature_importance)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=dt_feature_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Feature Importance - Decision Tree')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd304de",
   "metadata": {},
   "source": [
    "## 8. Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39012e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_pred = rf_classifier.predict(X_train)\n",
    "rf_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classifier trained successfully!\")\n",
    "print(f\"Number of trees: {rf_classifier.n_estimators}\")\n",
    "print(f\"Max depth: {rf_classifier.max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "rf_feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importance:\")\n",
    "display(rf_feature_importance)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=rf_feature_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Feature Importance - Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafe67c",
   "metadata": {},
   "source": [
    "## 9. Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae786bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# Calculate metrics for both models\n",
    "dt_train_metrics = calculate_metrics(y_train, dt_train_pred, 'Decision Tree (Train)')\n",
    "dt_test_metrics = calculate_metrics(y_test, dt_test_pred, 'Decision Tree (Test)')\n",
    "rf_train_metrics = calculate_metrics(y_train, rf_train_pred, 'Random Forest (Train)')\n",
    "rf_test_metrics = calculate_metrics(y_test, rf_test_pred, 'Random Forest (Test)')\n",
    "\n",
    "# Create performance comparison dataframe\n",
    "performance_df = pd.DataFrame([dt_train_metrics, dt_test_metrics, rf_train_metrics, rf_test_metrics])\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(performance_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    model_names = ['DT Train', 'DT Test', 'RF Train', 'RF Test']\n",
    "    values = performance_df[metric].values\n",
    "    colors = ['lightblue', 'blue', 'lightgreen', 'green']\n",
    "    \n",
    "    axes[i].bar(model_names, values, color=colors)\n",
    "    axes[i].set_title(f'{metric} Comparison')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for j, v in enumerate(values):\n",
    "        axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d442759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Decision Tree Confusion Matrix\n",
    "dt_cm = confusion_matrix(y_test, dt_test_pred)\n",
    "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Decision Tree - Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xticklabels(['No Churn', 'Churn'])\n",
    "axes[0].set_yticklabels(['No Churn', 'Churn'])\n",
    "\n",
    "# Random Forest Confusion Matrix\n",
    "rf_cm = confusion_matrix(y_test, rf_test_pred)\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Random Forest - Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_xticklabels(['No Churn', 'Churn'])\n",
    "axes[1].set_yticklabels(['No Churn', 'Churn'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed classification reports\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_test_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "print(\"\\\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_test_pred, target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651ea2c",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f25722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature importance between models\n",
    "feature_comparison = pd.merge(\n",
    "    dt_feature_importance,\n",
    "    rf_feature_importance,\n",
    "    on='feature',\n",
    "    suffixes=('_DT', '_RF')\n",
    ").sort_values('importance_RF', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Comparison (Top 10):\")\n",
    "display(feature_comparison.head(10))\n",
    "\n",
    "# Visualize feature importance comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_comparison.head(10)\n",
    "\n",
    "x = np.arange(len(top_features))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, top_features['importance_DT'], width, label='Decision Tree', alpha=0.8)\n",
    "plt.bar(x + width/2, top_features['importance_RF'], width, label='Random Forest', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance Comparison: Decision Tree vs Random Forest')\n",
    "plt.xticks(x, top_features['feature'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 features analysis\n",
    "print(\"TOP 3 FEATURES INFLUENCING CUSTOMER CHURN:\")\n",
    "print(\"\\nFrom Random Forest Model:\")\n",
    "top_3_rf = rf_feature_importance.head(3)\n",
    "for i, (_, row) in enumerate(top_3_rf.iterrows(), 1):\n",
    "    print(f\"{i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\nFrom Decision Tree Model:\")\n",
    "top_3_dt = dt_feature_importance.head(3)\n",
    "for i, (_, row) in enumerate(top_3_dt.iterrows(), 1):\n",
    "    print(f\"{i}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed646a8",
   "metadata": {},
   "source": [
    "## 11. Cross-Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdbd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation for both models\n",
    "print(\"Cross-Validation Results (5-fold):\")\n",
    "\n",
    "# Decision Tree Cross-Validation\n",
    "dt_cv_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nDecision Tree CV Scores: {dt_cv_scores}\")\n",
    "print(f\"Decision Tree CV Mean: {dt_cv_scores.mean():.4f} (+/- {dt_cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Random Forest Cross-Validation\n",
    "rf_cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nRandom Forest CV Scores: {rf_cv_scores}\")\n",
    "print(f\"Random Forest CV Mean: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Visualize cross-validation results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([dt_cv_scores, rf_cv_scores], labels=['Decision Tree', 'Random Forest'])\n",
    "plt.title('Cross-Validation Score Distribution')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e9897",
   "metadata": {},
   "source": [
    "## 12. Handle Overfitting with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Decision Tree\n",
    "print(\"Performing Grid Search for Decision Tree...\")\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "    'min_samples_leaf': [5, 10, 20]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best DT parameters: {dt_grid_search.best_params_}\")\n",
    "print(f\"Best DT CV score: {dt_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467df419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Random Forest\n",
    "print(\"Performing Grid Search for Random Forest...\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [10, 20],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best RF parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Best RF CV score: {rf_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfbb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train optimized models with best parameters\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with optimized models\n",
    "best_dt_pred = best_dt.predict(X_test)\n",
    "best_rf_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics for optimized models\n",
    "best_dt_metrics = calculate_metrics(y_test, best_dt_pred, 'Optimized Decision Tree')\n",
    "best_rf_metrics = calculate_metrics(y_test, best_rf_pred, 'Optimized Random Forest')\n",
    "\n",
    "# Compare original vs optimized models\n",
    "comparison_df = pd.DataFrame([\n",
    "    dt_test_metrics,\n",
    "    best_dt_metrics,\n",
    "    rf_test_metrics,\n",
    "    best_rf_metrics\n",
    "])\n",
    "\n",
    "print(\"Original vs Optimized Model Comparison:\")\n",
    "display(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e6a3b",
   "metadata": {},
   "source": [
    "## 13. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison\n",
    "print(\"COMPREHENSIVE MODEL PERFORMANCE ANALYSIS\")\n",
    "\n",
    "\n",
    "models_comparison = {\n",
    "    'Decision Tree (Original)': {\n",
    "        'Train Accuracy': accuracy_score(y_train, dt_train_pred),\n",
    "        'Test Accuracy': accuracy_score(y_test, dt_test_pred),\n",
    "        'CV Mean': dt_cv_scores.mean(),\n",
    "        'Overfitting': accuracy_score(y_train, dt_train_pred) - accuracy_score(y_test, dt_test_pred)\n",
    "    },\n",
    "    'Random Forest (Original)': {\n",
    "        'Train Accuracy': accuracy_score(y_train, rf_train_pred),\n",
    "        'Test Accuracy': accuracy_score(y_test, rf_test_pred),\n",
    "        'CV Mean': rf_cv_scores.mean(),\n",
    "        'Overfitting': accuracy_score(y_train, rf_train_pred) - accuracy_score(y_test, rf_test_pred)\n",
    "    },\n",
    "    'Decision Tree (Optimized)': {\n",
    "        'Train Accuracy': accuracy_score(y_train, best_dt.predict(X_train)),\n",
    "        'Test Accuracy': accuracy_score(y_test, best_dt_pred),\n",
    "        'CV Mean': dt_grid_search.best_score_,\n",
    "        'Overfitting': accuracy_score(y_train, best_dt.predict(X_train)) - accuracy_score(y_test, best_dt_pred)\n",
    "    },\n",
    "    'Random Forest (Optimized)': {\n",
    "        'Train Accuracy': accuracy_score(y_train, best_rf.predict(X_train)),\n",
    "        'Test Accuracy': accuracy_score(y_test, best_rf_pred),\n",
    "        'CV Mean': rf_grid_search.best_score_,\n",
    "        'Overfitting': accuracy_score(y_train, best_rf.predict(X_train)) - accuracy_score(y_test, best_rf_pred)\n",
    "    }\n",
    "}\n",
    "\n",
    "comparison_detailed_df = pd.DataFrame(models_comparison).T\n",
    "print(\"Detailed Model Comparison:\")\n",
    "display(comparison_detailed_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overfitting analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "models = list(models_comparison.keys())\n",
    "train_acc = [models_comparison[model]['Train Accuracy'] for model in models]\n",
    "test_acc = [models_comparison[model]['Test Accuracy'] for model in models]\n",
    "overfitting = [models_comparison[model]['Overfitting'] for model in models]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(x - width, train_acc, width, label='Train Accuracy', alpha=0.8)\n",
    "plt.bar(x, test_acc, width, label='Test Accuracy', alpha=0.8)\n",
    "plt.bar(x + width, [models_comparison[model]['CV Mean'] for model in models], width, label='CV Mean', alpha=0.8)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x, [m.replace(' ', '\\n') for m in models], rotation=0)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "colors = ['red' if x > 0.05 else 'green' for x in overfitting]\n",
    "plt.bar(x, overfitting, color=colors, alpha=0.7)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Overfitting (Train - Test)')\n",
    "plt.title('Overfitting Analysis')\n",
    "plt.xticks(x, [m.replace(' ', '\\n') for m in models], rotation=0)\n",
    "plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.5, label='Overfitting Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60429ce3",
   "metadata": {},
   "source": [
    "## 14. Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe57a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best performing model\n",
    "best_model_name = comparison_detailed_df['Test Accuracy'].idxmax()\n",
    "best_model_accuracy = comparison_detailed_df['Test Accuracy'].max()\n",
    "\n",
    "print(\"BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
    "\n",
    "print(f\"\\\\nBEST PERFORMING MODEL: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_model_accuracy:.4f}\")\n",
    "\n",
    "# Use the best Random Forest model for feature importance\n",
    "best_features = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\\\nTOP 5 CHURN PREDICTORS:\")\n",
    "for i, (_, row) in enumerate(best_features.head(5).iterrows(), 1):\n",
    "    print(f\"   {i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\\\nKEY BUSINESS INSIGHTS:\")\n",
    "\n",
    "# Analyze model performance\n",
    "if 'Random Forest' in best_model_name:\n",
    "    print(\"   Random Forest outperformed Decision Tree, indicating ensemble benefits\")\n",
    "    print(\"   Random Forest shows better generalization and reduced overfitting\")\n",
    "else:\n",
    "    print(\"   Decision Tree performed well with good interpretability\")\n",
    "\n",
    "# Overfitting analysis\n",
    "rf_overfitting = comparison_detailed_df.loc[best_model_name, 'Overfitting']\n",
    "if rf_overfitting < 0.05:\n",
    "    print(f\"   Model shows minimal overfitting ({rf_overfitting:.4f})\")\n",
    "else:\n",
    "    print(f\"   Model shows some overfitting ({rf_overfitting:.4f}) - consider further regularization\")\n",
    "\n",
    "print(f\"\\\\nACTIONABLE RECOMMENDATIONS FOR CUSTOMER RETENTION:\")\n",
    "\n",
    "# Generate recommendations based on top features\n",
    "top_3_features = best_features.head(3)['feature'].tolist()\n",
    "recommendations = {\n",
    "    'tenure': 'Focus on early customer engagement programs for new customers (first 12 months)',\n",
    "    'MonthlyCharges': 'Review pricing strategy and offer competitive packages for high-value customers',\n",
    "    'TotalCharges': 'Implement loyalty programs for long-term, high-spending customers',\n",
    "    'Contract': 'Incentivize longer-term contracts with discounts and benefits',\n",
    "    'PaymentMethod': 'Simplify payment processes and offer preferred payment incentives',\n",
    "    'InternetService': 'Improve service quality and offer service upgrades',\n",
    "    'gender': 'Develop targeted marketing campaigns for different customer segments'\n",
    "}\n",
    "\n",
    "for i, feature in enumerate(top_3_features, 1):\n",
    "    if feature in recommendations:\n",
    "        print(f\"   {i}. {feature.upper()}: {recommendations[feature]}\")\n",
    "    else:\n",
    "        print(f\"   {i}. {feature.upper()}: Analyze this feature further for targeted interventions\")\n",
    "\n",
    "print(f\"\\\\nIMPLEMENTATION STRATEGY:\")\n",
    "print(\"   1. Deploy the optimized Random Forest model for real-time churn prediction\")\n",
    "print(\"   2. Set up automated alerts for customers with high churn probability (>0.7)\")\n",
    "print(\"   3. Create targeted retention campaigns based on feature importance\")\n",
    "print(\"   4. Monitor model performance monthly and retrain quarterly\")\n",
    "print(\"   5. A/B test retention strategies on predicted high-risk customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Model Accuracy Comparison\n",
    "axes[0, 0].bar(['DT Original', 'DT Optimized', 'RF Original', 'RF Optimized'], \n",
    "               [comparison_detailed_df.loc[model, 'Test Accuracy'] for model in comparison_detailed_df.index],\n",
    "               color=['lightblue', 'blue', 'lightgreen', 'green'])\n",
    "axes[0, 0].set_title('Test Accuracy Comparison')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# 2. Top Features (Best Model)\n",
    "top_5_features = best_features.head(5)\n",
    "axes[0, 1].barh(top_5_features['feature'], top_5_features['importance'])\n",
    "axes[0, 1].set_title('Top 5 Most Important Features')\n",
    "axes[0, 1].set_xlabel('Importance')\n",
    "\n",
    "# 3. Overfitting Analysis\n",
    "overfitting_values = [comparison_detailed_df.loc[model, 'Overfitting'] for model in comparison_detailed_df.index]\n",
    "colors_overfitting = ['red' if x > 0.05 else 'green' for x in overfitting_values]\n",
    "axes[1, 0].bar(['DT Original', 'DT Optimized', 'RF Original', 'RF Optimized'], \n",
    "               overfitting_values, color=colors_overfitting, alpha=0.7)\n",
    "axes[1, 0].set_title('Overfitting Analysis')\n",
    "axes[1, 0].set_ylabel('Train - Test Accuracy')\n",
    "axes[1, 0].axhline(y=0.05, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. Churn Distribution\n",
    "churn_dist = df['Churn'].value_counts()\n",
    "axes[1, 1].pie(churn_dist.values, labels=churn_dist.index, autopct='%1.1f%%', \n",
    "               colors=['lightblue', 'lightcoral'])\n",
    "axes[1, 1].set_title('Original Churn Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nANALYSIS COMPLETE!\")\n",
    "print(\"Models trained and evaluated successfully\")\n",
    "print(\"Feature importance analysis completed\")\n",
    "print(\"Hyperparameter optimization performed\")\n",
    "print(\"Business recommendations generated\")\n",
    "print(f\"\\\\nBest Model: {best_model_name} with {best_model_accuracy:.2%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67f7f8",
   "metadata": {},
   "source": [
    "## Post Lab Analysis\n",
    "\n",
    "### Key Questions Answered:\n",
    "\n",
    "1. **Which model performed better and why?**\n",
    "   - The Random Forest model generally performs better due to:\n",
    "     - Ensemble learning reduces overfitting\n",
    "     - Better generalization to unseen data\n",
    "     - More robust feature importance estimates\n",
    "\n",
    "2. **Top 3 features influencing churn:**\n",
    "   - Based on feature importance analysis from the best model\n",
    "   - These features should be prioritized for retention strategies\n",
    "\n",
    "3. **Overfitting Analysis:**\n",
    "   - Decision Tree: Higher tendency to overfit\n",
    "   - Random Forest: Better control over overfitting\n",
    "   - Hyperparameter tuning helps reduce overfitting in both models\n",
    "\n",
    "### Next Steps:\n",
    "1. Try with different datasets (Credit Default, Bank Customer Churn)\n",
    "2. Experiment with other ensemble methods (XGBoost, AdaBoost)\n",
    "3. Implement cost-sensitive learning for imbalanced data\n",
    "4. Deploy model for real-time predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Total Time Invested:** 2 hours (Definition + Engagement)\n",
    "\n",
    "**Skills Developed:**\n",
    "- Data preprocessing and feature engineering\n",
    "- Decision Tree and Random Forest implementation\n",
    "- Model evaluation and comparison\n",
    "- Hyperparameter tuning and overfitting mitigation\n",
    "- Business insight generation from ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restored_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
