{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1cefb4-41e7-45f7-adcb-42ff44b37645",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-----------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39mTraceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "# Only import what's available\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "except ImportError:\n",
    "    print(\"statsmodels not available, ARIMA will not work\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93226575-ecf8-4a88-8297-b41bf207bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stock Price Prediction - Data Collection and Preprocessing\n",
    "This script downloads historical stock data and prepares it for model training\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2018-01-01\"\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "SEQUENCE_LENGTH = 60  # 60 days of history for prediction\n",
    "\n",
    "print(f\"Downloading data for {TICKER} from {START_DATE} to {END_DATE}\")\n",
    "\n",
    "# Download data\n",
    "try:\n",
    "    data = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
    "    print(f\"Downloaded {len(data)} days of data\")\n",
    "    \n",
    "    # Basic data exploration\n",
    "    print(\"\\nData Overview:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    # Plot the closing prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data['Close'])\n",
    "    plt.title(f'{TICKER} Stock Price')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('plots/stock_price_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Add technical indicators\n",
    "    def add_technical_indicators(df):\n",
    "        print(\"Adding technical indicators...\")\n",
    "        # Moving averages\n",
    "        df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "        df['MA50'] = df['Close'].rolling(window=50).mean()\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['20d_std'] = df['Close'].rolling(window=20).std()\n",
    "        df['upper_band'] = df['MA20'] + (df['20d_std'] * 2)\n",
    "        df['lower_band'] = df['MA20'] - (df['20d_std'] * 2)\n",
    "        \n",
    "        # RSI (14-day)\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # MACD\n",
    "        df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "        df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "        df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "        df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        \n",
    "        return df\n",
    "\n",
    "    data = add_technical_indicators(data)\n",
    "    \n",
    "    # Plot some technical indicators\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(data['Close'], label='Close Price')\n",
    "    plt.plot(data['MA20'], label='20-day MA')\n",
    "    plt.plot(data['MA50'], label='50-day MA')\n",
    "    plt.title(f'{TICKER} Price and Moving Averages')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(data['RSI'], label='RSI')\n",
    "    plt.axhline(y=70, color='r', linestyle='--')\n",
    "    plt.axhline(y=30, color='g', linestyle='--')\n",
    "    plt.title('Relative Strength Index (RSI)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(data['MACD'], label='MACD')\n",
    "    plt.plot(data['Signal_Line'], label='Signal Line')\n",
    "    plt.title('MACD and Signal Line')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/technical_indicators.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Remove NaN values\n",
    "    data.dropna(inplace=True)\n",
    "    print(f\"Data after removing NaN values: {len(data)} rows\")\n",
    "    \n",
    "    # Save the preprocessed data\n",
    "    data.to_csv('data/preprocessed_data.csv')\n",
    "    \n",
    "    # Feature selection\n",
    "    features = ['Close', 'Volume', 'MA20', 'MA50', 'RSI', 'MACD', 'upper_band', 'lower_band']\n",
    "    target = 'Close'\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data[features])\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=features, index=data.index)\n",
    "    \n",
    "    # Create sequences for LSTM\n",
    "    def create_sequences(data, seq_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            X.append(data[i:i+seq_length])\n",
    "            y.append(data[i+seq_length, 0])  # 'Close' is the first column\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(scaled_data, SEQUENCE_LENGTH)\n",
    "    print(f\"Created {len(X)} sequences of length {SEQUENCE_LENGTH}\")\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    split_ratio = 0.8\n",
    "    split_index = int(split_ratio * len(X))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    \n",
    "    print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Testing data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    \n",
    "    # Save processed data\n",
    "    np.save('data/X_train.npy', X_train)\n",
    "    np.save('data/y_train.npy', y_train)\n",
    "    np.save('data/X_test.npy', X_test)\n",
    "    np.save('data/y_test.npy', y_test)\n",
    "    \n",
    "    # Also save the scaler for later use\n",
    "    with open('data/scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    print(\"Data preprocessing completed successfully!\")\n",
    "    print(\"Files saved in 'data' directory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d903588-3576-4445-900e-18860d704b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stock data\n",
    "print(f\"Downloading data for {TICKER} from {START_DATE} to {END_DATE}...\")\n",
    "data = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
    "\n",
    "# Basic info\n",
    "print(f\"Downloaded {len(data)} days of data\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad48434-4306-46a5-a424-5ba3aad26666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the closing prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['Close'])\n",
    "plt.title(f'{TICKER} Stock Price History')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Volume traded\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(data.index, data['Volume'])\n",
    "plt.title(f'{TICKER} Trading Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f88cbf-a95a-46d5-9caa-2cad974482c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical indicators\n",
    "def add_technical_indicators(df):\n",
    "    print(\"Adding technical indicators...\")\n",
    "    # Moving averages\n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['20d_std'] = df['Close'].rolling(window=20).std()\n",
    "    df['upper_band'] = df['MA20'] + (df['20d_std'] * 2)\n",
    "    df['lower_band'] = df['MA20'] - (df['20d_std'] * 2)\n",
    "    \n",
    "    # RSI (14-day)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply technical indicators\n",
    "data = add_technical_indicators(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e45cf1-488f-44d6-952d-39d883400cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot technical indicators\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Close price, MA20, MA50\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(data.index, data['Close'], label='Close Price')\n",
    "plt.plot(data.index, data['MA20'], label='20-day MA')\n",
    "plt.plot(data.index, data['MA50'], label='50-day MA')\n",
    "plt.title(f'{TICKER} Close Price and Moving Averages')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: RSI\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(data.index, data['RSI'], label='RSI')\n",
    "plt.axhline(y=70, color='r', linestyle='--')\n",
    "plt.axhline(y=30, color='g', linestyle='--')\n",
    "plt.title('Relative Strength Index (RSI)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 3: MACD\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(data.index, data['MACD'], label='MACD')\n",
    "plt.plot(data.index, data['Signal_Line'], label='Signal Line')\n",
    "plt.title('MACD and Signal Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4246f58-5e16-420e-abce-00b6920c0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values\n",
    "data.dropna(inplace=True)\n",
    "print(f\"Data after removing NaN values: {len(data)} rows\")\n",
    "\n",
    "# Feature selection\n",
    "features = ['Close', 'Volume', 'MA20', 'MA50', 'RSI', 'MACD', 'upper_band', 'lower_band']\n",
    "target = 'Close'\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data[features])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=features, index=data.index)\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, 0])  # 'Close' is the first column\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_data, SEQUENCE_LENGTH)\n",
    "print(f\"Created {len(X)} sequences of length {SEQUENCE_LENGTH}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "split_index = int(SPLIT_RATIO * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Also prepare data for ARIMA (non-scaled)\n",
    "train_data = data['Close'][:int(SPLIT_RATIO * len(data))]\n",
    "test_data = data['Close'][int(SPLIT_RATIO * len(data)):]\n",
    "\n",
    "# Save test dates for later visualization\n",
    "test_dates = data.index[int(SPLIT_RATIO * len(data)) + SEQUENCE_LENGTH:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050f385-df0d-4477-82c9-9c95c054cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARIMA_AVAILABLE:\n",
    "    # Check stationarity\n",
    "    def check_stationarity(timeseries):\n",
    "        result = adfuller(timeseries)\n",
    "        print('ADF Statistic: %f' % result[0])\n",
    "        print('p-value: %f' % result[1])\n",
    "        print('Critical Values:')\n",
    "        for key, value in result[4].items():\n",
    "            print('\\t%s: %.3f' % (key, value))\n",
    "        \n",
    "        # If p-value is less than 0.05, data is stationary\n",
    "        if result[1] <= 0.05:\n",
    "            print(\"The time series is stationary\")\n",
    "        else:\n",
    "            print(\"The time series is not stationary\")\n",
    "\n",
    "    # Test stationarity\n",
    "    print(\"Testing stationarity of time series...\")\n",
    "    check_stationarity(train_data)\n",
    "\n",
    "    # Determine if differencing is needed\n",
    "    if adfuller(train_data)[1] > 0.05:\n",
    "        print(\"\\nApplying differencing to make the series stationary...\")\n",
    "        train_diff = train_data.diff().dropna()\n",
    "        print(\"After differencing:\")\n",
    "        check_stationarity(train_diff)\n",
    "        diff_order = 1\n",
    "    else:\n",
    "        train_diff = train_data\n",
    "        diff_order = 0\n",
    "\n",
    "    # Fit ARIMA model\n",
    "    print(\"\\nTraining ARIMA model...\")\n",
    "    try:\n",
    "        model = ARIMA(train_data, order=(5, diff_order, 1))\n",
    "        model_fit = model.fit()\n",
    "        print(\"ARIMA model summary:\")\n",
    "        print(model_fit.summary())\n",
    "\n",
    "        # Make predictions\n",
    "        print(\"\\nMaking predictions with ARIMA model...\")\n",
    "        arima_predictions = model_fit.forecast(steps=len(test_data))\n",
    "        \n",
    "        # Calculate error metrics\n",
    "        arima_rmse = math.sqrt(mean_squared_error(test_data, arima_predictions))\n",
    "        arima_mae = mean_absolute_error(test_data, arima_predictions)\n",
    "        arima_mape = np.mean(np.abs((test_data - arima_predictions) / test_data)) * 100\n",
    "        \n",
    "        print(f\"ARIMA RMSE: {arima_rmse:.2f}\")\n",
    "        print(f\"ARIMA MAE: {arima_mae:.2f}\")\n",
    "        print(f\"ARIMA MAPE: {arima_mape:.2f}%\")\n",
    "\n",
    "        # Plot results\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(train_data.index[-30:], train_data[-30:], label='Training Data')\n",
    "        plt.plot(test_data.index, test_data, label='Actual Price')\n",
    "        plt.plot(test_data.index, arima_predictions, label='ARIMA Predictions', color='red')\n",
    "        plt.title(f'ARIMA: Stock Price Prediction for {TICKER}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price (USD)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Make future predictions with ARIMA\n",
    "        print(\"\\nPredicting future prices with ARIMA...\")\n",
    "        arima_future = model_fit.forecast(steps=FUTURE_DAYS)\n",
    "        future_dates = pd.date_range(start=data.index[-1], periods=FUTURE_DAYS+1)[1:]\n",
    "        \n",
    "        arima_available_for_comparison = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ARIMA model: {e}\")\n",
    "        arima_available_for_comparison = False\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping ARIMA model due to missing dependencies\")\n",
    "    arima_available_for_comparison = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60c7e0-fdcc-4f39-a2f1-26932b5bd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LSTM_AVAILABLE:\n",
    "    print(\"Building LSTM model...\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    # Train model with early stopping\n",
    "    print(\"\\nTraining LSTM model...\")\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('LSTM Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions with LSTM model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform predictions to original scale\n",
    "    y_pred_full = np.zeros((len(y_pred), X_train.shape[2]))\n",
    "    y_pred_full[:, 0] = y_pred.flatten()\n",
    "    y_test_full = np.zeros((len(y_test), X_train.shape[2]))\n",
    "    y_test_full[:, 0] = y_test.flatten()\n",
    "\n",
    "    y_pred_original = scaler.inverse_transform(y_pred_full)[:, 0]\n",
    "    y_test_original = scaler.inverse_transform(y_test_full)[:, 0]\n",
    "\n",
    "    # Calculate metrics\n",
    "    lstm_rmse = math.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "    lstm_mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    lstm_mape = np.mean(np.abs((y_test_original - y_pred_original) / y_test_original)) * 100\n",
    "    \n",
    "    print(f\"LSTM RMSE: {lstm_rmse:.2f}\")\n",
    "    print(f\"LSTM MAE: {lstm_mae:.2f}\")\n",
    "    print(f\"LSTM MAPE: {lstm_mape:.2f}%\")\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(test_dates, y_test_original, label='Actual Price')\n",
    "    plt.plot(test_dates, y_pred_original, label='LSTM Predictions', color='green')\n",
    "    plt.title(f'LSTM: Stock Price Prediction for {TICKER}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate future predictions\n",
    "    print(\"\\nPredicting future prices with LSTM...\")\n",
    "    last_sequence = X_test[-1:].copy()\n",
    "    lstm_future = []\n",
    "\n",
    "    for _ in range(FUTURE_DAYS):\n",
    "        # Make prediction with current sequence\n",
    "        next_pred = model.predict(last_sequence)\n",
    "        lstm_future.append(next_pred[0, 0])\n",
    "        \n",
    "        # Create a new sequence by:\n",
    "        # 1. Dropping the first time step\n",
    "        # 2. Appending the new prediction\n",
    "        last_seq = last_sequence[0]\n",
    "        new_seq = np.append(last_seq[1:, :], [[next_pred[0, 0]] + [0] * (last_seq.shape[1]-1)], axis=0)\n",
    "        last_sequence[0] = new_seq\n",
    "    \n",
    "    # Scale back the predictions\n",
    "    lstm_future_array = np.array(lstm_future).reshape(-1, 1)\n",
    "    lstm_future_full = np.zeros((len(lstm_future), X_train.shape[2]))\n",
    "    lstm_future_full[:, 0] = lstm_future_array.flatten()\n",
    "    lstm_future_original = scaler.inverse_transform(lstm_future_full)[:, 0]\n",
    "    \n",
    "    # Create future dates\n",
    "    future_dates = pd.date_range(start=test_dates[-1], periods=FUTURE_DAYS+1)[1:]\n",
    "    \n",
    "    lstm_available_for_comparison = True\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping LSTM model due to missing dependencies\")\n",
    "    lstm_available_for_comparison = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af96acd-3457-472a-a56e-d8ce8c228937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions visualization\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['Close'][-60:].index, data['Close'][-60:], label='Historical Price', color='blue')\n",
    "\n",
    "if 'arima_available_for_comparison' in locals() and arima_available_for_comparison:\n",
    "    plt.plot(future_dates, arima_future, label='ARIMA Forecast', color='red', linestyle='--')\n",
    "    \n",
    "if 'lstm_available_for_comparison' in locals() and lstm_available_for_comparison:\n",
    "    plt.plot(future_dates, lstm_future_original, label='LSTM Forecast', color='green', linestyle='-.')\n",
    "\n",
    "plt.title(f'{TICKER} Stock Price Forecast (Next {FUTURE_DAYS} Days)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Compare model performance if both are available\n",
    "if ('arima_available_for_comparison' in locals() and arima_available_for_comparison and\n",
    "    'lstm_available_for_comparison' in locals() and lstm_available_for_comparison):\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison_results = {\n",
    "        'ARIMA_RMSE': arima_rmse,\n",
    "        'ARIMA_MAE': arima_mae,\n",
    "        'ARIMA_MAPE': arima_mape,\n",
    "        'LSTM_RMSE': lstm_rmse,\n",
    "        'LSTM_MAE': lstm_mae,\n",
    "        'LSTM_MAPE': lstm_mape,\n",
    "    }\n",
    "    \n",
    "    # Compare models\n",
    "    if lstm_rmse < arima_rmse:\n",
    "        comparison_results['Better_Model'] = 'LSTM'\n",
    "        print(\"\\nLSTM model performed better based on RMSE\")\n",
    "    else:\n",
    "        comparison_results['Better_Model'] = 'ARIMA'\n",
    "        print(\"\\nARIMA model performed better based on RMSE\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame([comparison_results])\n",
    "    display(comparison_df)\n",
    "\n",
    "    # Create dataframe for future predictions\n",
    "    future_df = pd.DataFrame({\n",
    "        'Date': future_dates,\n",
    "        'ARIMA_Forecast': arima_future,\n",
    "        'LSTM_Forecast': lstm_future_original\n",
    "    }).set_index('Date')\n",
    "    \n",
    "    print(\"\\nFuture price predictions:\")\n",
    "    display(future_df.head())\n",
    "\n",
    "    # Save the predictions if needed\n",
    "    future_df.to_csv('results/future_predictions_combined.csv')\n",
    "    print(\"Future predictions saved to 'results/future_predictions_combined.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nCould not compare models because one or both models were not available\")\n",
    "    \n",
    "    # Check if at least one model is available for future predictions\n",
    "    if 'lstm_available_for_comparison' in locals() and lstm_available_for_comparison:\n",
    "        future_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'LSTM_Forecast': lstm_future_original\n",
    "        }).set_index('Date')\n",
    "        \n",
    "        print(\"\\nFuture price predictions from LSTM:\")\n",
    "        display(future_df.head())\n",
    "        \n",
    "    elif 'arima_available_for_comparison' in locals() and arima_available_for_comparison:\n",
    "        future_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'ARIMA_Forecast': arima_future\n",
    "        }).set_index('Date')\n",
    "        \n",
    "        print(\"\\nFuture price predictions from ARIMA:\")\n",
    "        display(future_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18bd1096-d894-401a-b92a-5c5390a5ffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Price Prediction Project - Summary\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TICKER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-----------\u001b[39m",
      "\u001b[31mNameError\u001b[39mTraceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStock Price Prediction Project - Summary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m----------------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStock Ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mTICKER\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate Range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining/Testing Split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPLIT_RATIO*\u001b[32m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[32m1\u001b[39m-SPLIT_RATIO)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'TICKER' is not defined"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(f\"Stock Price Prediction Project - Summary\")\n",
    "print(f\"----------------------------------------\")\n",
    "print(f\"Stock Ticker: {TICKER}\")\n",
    "print(f\"Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Training/Testing Split: {SPLIT_RATIO*100}%/{(1-SPLIT_RATIO)*100}%\")\n",
    "\n",
    "if 'arima_available_for_comparison' in locals() and arima_available_for_comparison:\n",
    "    print(f\"\\nARIMA Model Performance:\")\n",
    "    print(f\"  RMSE: {arima_rmse:.2f}\")\n",
    "    print(f\"  MAE: {arima_mae:.2f}\")\n",
    "    print(f\"  MAPE: {arima_mape:.2f}%\")\n",
    "\n",
    "if 'lstm_available_for_comparison' in locals() and lstm_available_for_comparison:\n",
    "    print(f\"\\nLSTM Model Performance:\")\n",
    "    print(f\"  RMSE: {lstm_rmse:.2f}\")\n",
    "    print(f\"  MAE: {lstm_mae:.2f}\")\n",
    "    print(f\"  MAPE: {lstm_mape:.2f}%\")\n",
    "\n",
    "# Save the notebook for future reference\n",
    "print(\"\\nRemember to save your notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f590db-113e-4297-9c0b-566efa214660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
