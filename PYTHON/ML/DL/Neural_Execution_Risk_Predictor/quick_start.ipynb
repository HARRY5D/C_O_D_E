{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "````xml\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "# Quick Start Guide - Neural Execution Risk Predictor\n",
    "\n",
    "This notebook provides a streamlined workflow to get started quickly.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Generate data\n",
    "3. Train model\n",
    "4. Test predictions\n",
    "5. Start API\n",
    "\n",
    "Let's begin! ðŸš€\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Step 1: Check if running in the correct directory\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = r\"D:\\JAVA\\CODE\\PYTHON\\ML\\DL\\Neural Execution Risk Predictor\"\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"âœ“ Working directory: {os.getcwd()}\")\n",
    "print(f\"\\nProject structure:\")\n",
    "for item in os.listdir():\n",
    "    print(f\"  - {item}\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Step 2: Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages.\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Install requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"âœ“ All dependencies installed!\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Step 3: Generate Dataset\n",
    "\n",
    "We'll generate data from two sources:\n",
    "1. BPI Challenge 2012 XES file (if available)\n",
    "2. Synthetic execution plans\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Check if XES file exists\n",
    "xes_file = \"new_BPI_Challenge_2012.xes\"\n",
    "xes_exists = os.path.exists(xes_file)\n",
    "\n",
    "if xes_exists:\n",
    "    print(f\"âœ“ Found XES file: {xes_file}\")\n",
    "    print(\"  Will extract features from BPI Challenge data\")\n",
    "else:\n",
    "    print(f\"âš  XES file not found: {xes_file}\")\n",
    "    print(\"  Will use synthetic data only\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Generate BPI features (if XES file exists)\n",
    "if xes_exists:\n",
    "    print(\"Extracting BPI features...\")\n",
    "    %run scripts/extract_bpi_features.py\n",
    "    print(\"\\nâœ“ BPI features extracted!\")\n",
    "else:\n",
    "    print(\"Skipping BPI extraction (file not found)\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Generate synthetic plans\n",
    "print(\"Generating synthetic execution plans...\")\n",
    "%run scripts/generate_synthetic_plans.py\n",
    "print(\"\\nâœ“ Synthetic plans generated!\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Combine datasets\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data\"\n",
    "synthetic_path = os.path.join(data_dir, \"synthetic_plans.csv\")\n",
    "combined_path = os.path.join(data_dir, \"execution_risk_dataset.csv\")\n",
    "\n",
    "# Load synthetic data\n",
    "df_synthetic = pd.read_csv(synthetic_path)\n",
    "df_synthetic = df_synthetic.drop(columns=['plan_id'])\n",
    "\n",
    "# If BPI data exists, combine; otherwise use synthetic only\n",
    "bpi_path = os.path.join(data_dir, \"bpi_features.csv\")\n",
    "if os.path.exists(bpi_path):\n",
    "    print(\"Combining BPI + Synthetic data...\")\n",
    "    df_bpi = pd.read_csv(bpi_path)\n",
    "    df_bpi = df_bpi.drop(columns=['case_id'])\n",
    "    df_combined = pd.concat([df_bpi, df_synthetic], ignore_index=True)\n",
    "else:\n",
    "    print(\"Using synthetic data only...\")\n",
    "    df_combined = df_synthetic\n",
    "\n",
    "# Shuffle and save\n",
    "df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_combined.to_csv(combined_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Combined dataset saved: {combined_path}\")\n",
    "print(f\"  Total samples: {len(df_combined)}\")\n",
    "print(f\"\\nRisk distribution:\")\n",
    "print(df_combined['failure_label'].value_counts().sort_index())\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Step 4: Train Model\n",
    "\n",
    "Now we'll train the neural network!\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Train the model\n",
    "print(\"Starting model training...\\n\")\n",
    "%run model/train.py\n",
    "\n",
    "print(\"\\nâœ“ Model training complete!\")\n",
    "print(\"  Model saved to: model/risk_model.h5\")\n",
    "print(\"  Scaler saved to: model/scaler.joblib\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Step 5: Test Predictions\n",
    "\n",
    "Let's test the trained model with sample inputs.\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load model and scaler\n",
    "model = keras.models.load_model(\"model/risk_model.h5\")\n",
    "scaler = joblib.load(\"model/scaler.joblib\")\n",
    "\n",
    "print(\"âœ“ Model and scaler loaded!\\n\")\n",
    "\n",
    "# Test samples\n",
    "test_samples = [\n",
    "    {\n",
    "        \"name\": \"ðŸŸ¢ Low Risk - Simple Execution\",\n",
    "        \"features\": [3, 2, 2, 0, 1500, 1, 0, 1, 60]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ðŸŸ¡ Medium Risk - Moderate Complexity\",\n",
    "        \"features\": [8, 4, 4, 1, 6000, 3, 2, 2, 180]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ðŸ”´ High Risk - Complex Execution\",\n",
    "        \"features\": [18, 8, 7, 1, 15000, 6, 12, 4, 500]\n",
    "    }\n",
    "]\n",
    "\n",
    "risk_labels = [\"LOW\", \"MEDIUM\", \"HIGH\"]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for sample in test_samples:\n",
    "    # Prepare input\n",
    "    features = np.array([sample[\"features\"]])\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Predict\n",
    "    probs = model.predict(features_scaled, verbose=0)[0]\n",
    "    predicted_class = np.argmax(probs)\n",
    "    confidence = probs[predicted_class]\n",
    "    \n",
    "    print(f\"\\n{sample['name']}\")\n",
    "    print(f\"  Prediction: {risk_labels[predicted_class]}\")\n",
    "    print(f\"  Confidence: {confidence:.2%}\")\n",
    "    print(f\"  Probabilities: LOW={probs[0]:.3f}, MED={probs[1]:.3f}, HIGH={probs[2]:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ All predictions successful!\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## Step 6: Start API (Optional)\n",
    "\n",
    "To start the FastAPI service, run this in a separate terminal:\n",
    "\n",
    "```bash\n",
    "cd \"D:\\JAVA\\CODE\\PYTHON\\ML\\DL\\Neural Execution Risk Predictor\"\n",
    "uvicorn api.main:app --reload\n",
    "```\n",
    "\n",
    "Then access:\n",
    "- **API Docs**: http://localhost:8000/docs\n",
    "- **Health Check**: http://localhost:8000/health\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"code\">\n",
    "# Test API (if running)\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000/health\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ“ API is running!\")\n",
    "        print(f\"  Response: {response.json()}\")\n",
    "        print(\"\\n  Access docs at: http://localhost:8000/docs\")\n",
    "    else:\n",
    "        print(\"âš  API returned error\")\n",
    "except:\n",
    "    print(\"â„¹ API is not running\")\n",
    "    print(\"\\n  Start it with:\")\n",
    "    print(\"  uvicorn api.main:app --reload\")\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell language=\"markdown\">\n",
    "## ðŸŽ‰ Quick Start Complete!\n",
    "\n",
    "You've successfully:\n",
    "- âœ… Generated training data\n",
    "- âœ… Trained the neural network\n",
    "- âœ… Tested predictions\n",
    "- âœ… (Optional) Started the API\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Explore the full notebook**: `neural_execution_risk_predictor.ipynb`\n",
    "   - Detailed EDA and visualizations\n",
    "   - Feature importance analysis\n",
    "   - Error analysis\n",
    "\n",
    "2. **Check evaluation metrics**: Run `model/evaluate.py`\n",
    "\n",
    "3. **Test the API**: Run `test_api.py`\n",
    "\n",
    "4. **Deploy with Docker**:\n",
    "   ```bash\n",
    "   docker build -t neural-risk-predictor .\n",
    "   docker run -p 8000:8000 neural-risk-predictor\n",
    "   ```\n",
    "\n",
    "5. **Read the README**: Complete documentation and architecture details\n",
    "\n",
    "---\n",
    "\n",
    "**Have fun building safer agent systems!** ðŸš€\n",
    "</VSCode.Cell>\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
