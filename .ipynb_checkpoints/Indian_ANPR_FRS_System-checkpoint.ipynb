{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a4e227",
   "metadata": {},
   "source": [
    "# Indian Vehicle Number Plate Recognition & Facial Recognition System\n",
    "\n",
    "A focused implementation combining:\n",
    "- **Automatic Number Plate Recognition (ANPR)** optimized for Indian number plates\n",
    "- **Facial Recognition System (FRS)** for person identification\n",
    "\n",
    "## Features:\n",
    "- Real-time processing from webcam or video files\n",
    "- Indian number plate format detection\n",
    "- EasyOCR for accurate text extraction\n",
    "- FaceNet-based facial recognition\n",
    "- Integrated processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd42dc",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python easyocr facenet-pytorch scikit-learn numpy matplotlib pillow tensorflow\n",
    "!pip install keras-facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9db87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_facenet import FaceNet\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import uuid\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe130f3",
   "metadata": {},
   "source": [
    "## 2. Indian Number Plate Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianANPR:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Indian ANPR system with EasyOCR\"\"\"\n",
    "        self.reader = easyocr.Reader(['en'], gpu=True)  # Enable GPU if available\n",
    "        \n",
    "        # Indian number plate patterns\n",
    "        self.indian_patterns = [\n",
    "            r'[A-Z]{2}\\s?[0-9]{1,2}\\s?[A-Z]{1,2}\\s?[0-9]{1,4}',  # Standard format: XX 00 XX 0000\n",
    "            r'[A-Z]{2}[0-9]{1,2}[A-Z]{1,2}[0-9]{1,4}',           # Without spaces\n",
    "            r'[0-9]{2}\\s?BH\\s?[0-9]{4}\\s?[A-Z]{2}',              # Bharat series\n",
    "            r'[0-9]{2}BH[0-9]{4}[A-Z]{2}',                        # Bharat series without spaces\n",
    "        ]\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('anpr_results', exist_ok=True)\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply bilateral filter to reduce noise while keeping edges sharp\n",
    "        filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "        \n",
    "        # Find edges\n",
    "        edged = cv2.Canny(filtered, 30, 200)\n",
    "        \n",
    "        return gray, filtered, edged\n",
    "    \n",
    "    def find_license_plate_contours(self, edged_image):\n",
    "        \"\"\"Find potential license plate contours\"\"\"\n",
    "        contours, _ = cv2.findContours(edged_image.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "        \n",
    "        license_plate_contours = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate contour\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.018 * perimeter, True)\n",
    "            \n",
    "            # Check if contour has 4 corners (rectangle-like)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h\n",
    "                \n",
    "                # Indian license plates typically have aspect ratio between 2:1 and 4:1\n",
    "                if 2.0 <= aspect_ratio <= 4.5 and w > 100 and h > 30:\n",
    "                    license_plate_contours.append((x, y, w, h, contour))\n",
    "        \n",
    "        return license_plate_contours\n",
    "    \n",
    "    def extract_text_from_roi(self, image, roi):\n",
    "        \"\"\"Extract text from Region of Interest using EasyOCR\"\"\"\n",
    "        x, y, w, h = roi[:4]\n",
    "        plate_region = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize for better OCR\n",
    "        plate_region = cv2.resize(plate_region, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Apply additional preprocessing\n",
    "        plate_gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n",
    "        plate_thresh = cv2.threshold(plate_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        \n",
    "        # Use EasyOCR to extract text\n",
    "        try:\n",
    "            results = self.reader.readtext(plate_thresh)\n",
    "            if results:\n",
    "                # Combine all detected text\n",
    "                text = ' '.join([result[1] for result in results if result[2] > 0.5])\n",
    "                return self.validate_indian_plate(text), plate_region\n",
    "        except Exception as e:\n",
    "            print(f\"OCR Error: {e}\")\n",
    "        \n",
    "        return None, plate_region\n",
    "    \n",
    "    def validate_indian_plate(self, text):\n",
    "        \"\"\"Validate if text matches Indian number plate patterns\"\"\"\n",
    "        if not text:\n",
    "            return None\n",
    "            \n",
    "        # Clean the text\n",
    "        cleaned_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "        \n",
    "        # Check against Indian patterns\n",
    "        for pattern in self.indian_patterns:\n",
    "            if re.match(pattern, text.upper()):\n",
    "                return text.upper()\n",
    "            if re.match(pattern, cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        # If no exact match, check if it looks like a valid plate\n",
    "        if len(cleaned_text) >= 6 and len(cleaned_text) <= 10:\n",
    "            # Basic validation: should have letters and numbers\n",
    "            if re.search(r'[A-Z]', cleaned_text) and re.search(r'[0-9]', cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def process_image(self, image):\n",
    "        \"\"\"Process image and detect Indian number plates\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Preprocess image\n",
    "        gray, filtered, edged = self.preprocess_image(image)\n",
    "        \n",
    "        # Find license plate contours\n",
    "        plate_contours = self.find_license_plate_contours(edged)\n",
    "        \n",
    "        # Process each potential plate\n",
    "        for i, contour_data in enumerate(plate_contours):\n",
    "            plate_text, plate_region = self.extract_text_from_roi(image, contour_data)\n",
    "            \n",
    "            if plate_text:\n",
    "                results.append({\n",
    "                    'text': plate_text,\n",
    "                    'region': plate_region,\n",
    "                    'bbox': contour_data[:4],\n",
    "                    'confidence': 0.8  # Placeholder confidence\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_result(self, plate_text, plate_region, timestamp=None):\n",
    "        \"\"\"Save detection result\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save image\n",
    "        img_filename = f\"anpr_results/plate_{timestamp}_{uuid.uuid4().hex[:6]}.jpg\"\n",
    "        cv2.imwrite(img_filename, plate_region)\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_filename = \"anpr_results/detections.csv\"\n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([timestamp, plate_text, img_filename])\n",
    "        \n",
    "        return img_filename\n",
    "\n",
    "# Initialize ANPR system\n",
    "anpr = IndianANPR()\n",
    "print(\"Indian ANPR system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ed8d3",
   "metadata": {},
   "source": [
    "## 3. Facial Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Facial Recognition System\"\"\"\n",
    "        self.facenet = FaceNet()\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.known_faces = {}\n",
    "        self.known_embeddings = []\n",
    "        self.known_names = []\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('face_results', exist_ok=True)\n",
    "        os.makedirs('known_faces', exist_ok=True)\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces in image using Haar Cascade\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        return faces\n",
    "    \n",
    "    def extract_face_embedding(self, face_image):\n",
    "        \"\"\"Extract face embedding using FaceNet\"\"\"\n",
    "        # Resize to 160x160 (FaceNet input size)\n",
    "        face_resized = cv2.resize(face_image, (160, 160))\n",
    "        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_expanded = np.expand_dims(face_rgb, axis=0)\n",
    "        \n",
    "        # Get embedding\n",
    "        embedding = self.facenet.embeddings(face_expanded)\n",
    "        return embedding[0]\n",
    "    \n",
    "    def add_known_face(self, image, name):\n",
    "        \"\"\"Add a known face to the database\"\"\"\n",
    "        faces = self.detect_faces(image)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            print(f\"No face detected for {name}\")\n",
    "            return False\n",
    "        \n",
    "        if len(faces) > 1:\n",
    "            print(f\"Multiple faces detected for {name}. Using the largest one.\")\n",
    "        \n",
    "        # Use the largest face\n",
    "        face = max(faces, key=lambda x: x[2] * x[3])\n",
    "        x, y, w, h = face\n",
    "        face_image = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Extract embedding\n",
    "        embedding = self.extract_face_embedding(face_image)\n",
    "        \n",
    "        # Store\n",
    "        self.known_embeddings.append(embedding)\n",
    "        self.known_names.append(name)\n",
    "        \n",
    "        # Save face image\n",
    "        face_filename = f\"known_faces/{name}_{len(self.known_embeddings)}.jpg\"\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "        \n",
    "        print(f\"Added {name} to known faces database\")\n",
    "        return True\n",
    "    \n",
    "    def recognize_faces(self, image, threshold=0.6):\n",
    "        \"\"\"Recognize faces in image\"\"\"\n",
    "        if len(self.known_embeddings) == 0:\n",
    "            return []\n",
    "        \n",
    "        faces = self.detect_faces(image)\n",
    "        results = []\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_image = image[y:y+h, x:x+w]\n",
    "            \n",
    "            try:\n",
    "                # Extract embedding\n",
    "                embedding = self.extract_face_embedding(face_image)\n",
    "                \n",
    "                # Compare with known faces\n",
    "                best_match = None\n",
    "                best_distance = float('inf')\n",
    "                \n",
    "                for i, known_embedding in enumerate(self.known_embeddings):\n",
    "                    distance = np.linalg.norm(embedding - known_embedding)\n",
    "                    \n",
    "                    if distance < best_distance:\n",
    "                        best_distance = distance\n",
    "                        best_match = self.known_names[i]\n",
    "                \n",
    "                # Determine if it's a match\n",
    "                if best_distance < threshold:\n",
    "                    name = best_match\n",
    "                    confidence = 1 - (best_distance / threshold)\n",
    "                else:\n",
    "                    name = \"Unknown\"\n",
    "                    confidence = 0.0\n",
    "                \n",
    "                results.append({\n",
    "                    'name': name,\n",
    "                    'confidence': confidence,\n",
    "                    'bbox': (x, y, w, h),\n",
    "                    'face_image': face_image\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing face: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_detection(self, face_image, name, confidence, timestamp=None):\n",
    "        \"\"\"Save face detection result\"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save image\n",
    "        img_filename = f\"face_results/face_{timestamp}_{name}_{uuid.uuid4().hex[:6]}.jpg\"\n",
    "        cv2.imwrite(img_filename, face_image)\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_filename = \"face_results/recognitions.csv\"\n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([timestamp, name, confidence, img_filename])\n",
    "        \n",
    "        return img_filename\n",
    "\n",
    "# Initialize Facial Recognition system\n",
    "frs = FacialRecognitionSystem()\n",
    "print(\"Facial Recognition system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0affcbf",
   "metadata": {},
   "source": [
    "## 4. Integrated ANPR + FRS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedANPR_FRS:\n",
    "    def __init__(self, anpr_system, frs_system):\n",
    "        \"\"\"Initialize integrated system\"\"\"\n",
    "        self.anpr = anpr_system\n",
    "        self.frs = frs_system\n",
    "        \n",
    "        # Create combined results directory\n",
    "        os.makedirs('integrated_results', exist_ok=True)\n",
    "        \n",
    "        # Initialize CSV for combined results\n",
    "        self.init_combined_csv()\n",
    "    \n",
    "    def init_combined_csv(self):\n",
    "        \"\"\"Initialize CSV file for combined results\"\"\"\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        \n",
    "        # Create header if file doesn't exist\n",
    "        if not os.path.exists(csv_filename):\n",
    "            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    'timestamp', 'plate_text', 'plate_confidence', \n",
    "                    'face_name', 'face_confidence', 'plate_image', 'face_image'\n",
    "                ])\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process single frame for both ANPR and face recognition\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Process ANPR\n",
    "        plate_results = self.anpr.process_image(frame)\n",
    "        \n",
    "        # Process Face Recognition\n",
    "        face_results = self.frs.recognize_faces(frame)\n",
    "        \n",
    "        # Combine results\n",
    "        combined_results = {\n",
    "            'timestamp': timestamp,\n",
    "            'plates': plate_results,\n",
    "            'faces': face_results,\n",
    "            'frame': frame.copy()\n",
    "        }\n",
    "        \n",
    "        # Save combined results\n",
    "        self.save_combined_results(combined_results)\n",
    "        \n",
    "        return combined_results\n",
    "    \n",
    "    def save_combined_results(self, results):\n",
    "        \"\"\"Save combined ANPR and FRS results\"\"\"\n",
    "        timestamp = results['timestamp']\n",
    "        \n",
    "        # Prepare data for CSV\n",
    "        plate_text = \"\"\n",
    "        plate_confidence = 0.0\n",
    "        plate_image = \"\"\n",
    "        \n",
    "        if results['plates']:\n",
    "            best_plate = max(results['plates'], key=lambda x: x['confidence'])\n",
    "            plate_text = best_plate['text']\n",
    "            plate_confidence = best_plate['confidence']\n",
    "            plate_image = self.anpr.save_result(plate_text, best_plate['region'], timestamp)\n",
    "        \n",
    "        face_name = \"\"\n",
    "        face_confidence = 0.0\n",
    "        face_image = \"\"\n",
    "        \n",
    "        if results['faces']:\n",
    "            best_face = max(results['faces'], key=lambda x: x['confidence'])\n",
    "            face_name = best_face['name']\n",
    "            face_confidence = best_face['confidence']\n",
    "            face_image = self.frs.save_detection(\n",
    "                best_face['face_image'], face_name, face_confidence, timestamp\n",
    "            )\n",
    "        \n",
    "        # Save to combined CSV\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp, plate_text, plate_confidence,\n",
    "                face_name, face_confidence, plate_image, face_image\n",
    "            ])\n",
    "    \n",
    "    def draw_detections(self, frame, results):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Draw license plates\n",
    "        for plate in results['plates']:\n",
    "            x, y, w, h = plate['bbox']\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(output_frame, f\"Plate: {plate['text']}\", \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw faces\n",
    "        for face in results['faces']:\n",
    "            x, y, w, h = face['bbox']\n",
    "            color = (0, 255, 255) if face['name'] != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            label = f\"{face['name']} ({face['confidence']:.2f})\"\n",
    "            cv2.putText(output_frame, label, \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        return output_frame\n",
    "\n",
    "# Initialize integrated system\n",
    "integrated_system = IntegratedANPR_FRS(anpr, frs)\n",
    "print(\"Integrated ANPR + FRS system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c1091",
   "metadata": {},
   "source": [
    "## 5. Setup Known Faces Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add known faces from images\n",
    "def add_sample_faces():\n",
    "    \"\"\"Add sample faces to the database\"\"\"\n",
    "    # You can add your own face images here\n",
    "    # Example: Load images from a directory\n",
    "    \n",
    "    sample_faces_dir = \"sample_faces\"\n",
    "    if os.path.exists(sample_faces_dir):\n",
    "        for filename in os.listdir(sample_faces_dir):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                image_path = os.path.join(sample_faces_dir, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    frs.add_known_face(image, name)\n",
    "                    print(f\"Added {name} to database\")\n",
    "    else:\n",
    "        print(\"Sample faces directory not found. Create 'sample_faces' folder and add face images.\")\n",
    "        print(\"Or use the webcam capture function below to add faces.\")\n",
    "\n",
    "# Add sample faces\n",
    "add_sample_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3028df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture and add face from webcam\n",
    "def capture_and_add_face(name):\n",
    "    \"\"\"Capture face from webcam and add to database\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Capturing face for {name}. Press SPACE to capture, ESC to cancel.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect faces for preview\n",
    "        faces = frs.detect_faces(frame)\n",
    "        \n",
    "        # Draw rectangles around faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Capturing: {name}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"SPACE: Capture, ESC: Cancel\", (10, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Face', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 32:  # SPACE key\n",
    "            if frs.add_known_face(frame, name):\n",
    "                print(f\"Successfully added {name}!\")\n",
    "            else:\n",
    "                print(f\"Failed to add {name}. Make sure face is clearly visible.\")\n",
    "            break\n",
    "        elif key == 27:  # ESC key\n",
    "            print(\"Capture cancelled\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "# capture_and_add_face(\"John_Doe\")\n",
    "print(\"To add a face using webcam, call: capture_and_add_face('PersonName')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e05a6",
   "metadata": {},
   "source": [
    "## 6. Test with Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample image\n",
    "def test_sample_image(image_path):\n",
    "    \"\"\"Test the system with a sample image\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} not found\")\n",
    "        return\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not load image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    \n",
    "    # Process with integrated system\n",
    "    results = integrated_system.process_frame(image)\n",
    "    \n",
    "    # Draw detections\n",
    "    output_image = integrated_system.draw_detections(image, results)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Detected Results')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nDetection Results:\")\n",
    "    print(f\"Timestamp: {results['timestamp']}\")\n",
    "    \n",
    "    if results['plates']:\n",
    "        print(\"\\nLicense Plates Detected:\")\n",
    "        for i, plate in enumerate(results['plates']):\n",
    "            print(f\"  {i+1}. Text: {plate['text']}, Confidence: {plate['confidence']:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nNo license plates detected\")\n",
    "    \n",
    "    if results['faces']:\n",
    "        print(\"\\nFaces Recognized:\")\n",
    "        for i, face in enumerate(results['faces']):\n",
    "            print(f\"  {i+1}. Name: {face['name']}, Confidence: {face['confidence']:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nNo faces recognized\")\n",
    "\n",
    "# Test with sample image (uncomment and provide image path)\n",
    "# test_sample_image(\"path/to/your/test_image.jpg\")\n",
    "print(\"To test with an image, call: test_sample_image('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60729dae",
   "metadata": {},
   "source": [
    "## 7. Real-time Processing (Webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realtime_detection():\n",
    "    \"\"\"Run real-time detection from webcam\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"Starting real-time detection. Press 'q' to quit.\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process frame\n",
    "            results = integrated_system.process_frame(frame)\n",
    "            \n",
    "            # Draw detections\n",
    "            output_frame = integrated_system.draw_detections(frame, results)\n",
    "            \n",
    "            # Add timestamp\n",
    "            timestamp_text = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            cv2.putText(output_frame, timestamp_text, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('ANPR + FRS Real-time', output_frame)\n",
    "            \n",
    "            # Check for quit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping detection...\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Real-time detection stopped\")\n",
    "\n",
    "# Uncomment to run real-time detection\n",
    "# run_realtime_detection()\n",
    "print(\"To start real-time detection, call: run_realtime_detection()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5f106",
   "metadata": {},
   "source": [
    "## 8. Process Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_file(video_path, output_path=None, save_frames=False):\n",
    "    \"\"\"Process a video file for ANPR and FRS\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file {video_path} not found\")\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"Resolution: {width}x{height}, FPS: {fps}, Total frames: {total_frames}\")\n",
    "    \n",
    "    # Setup output video writer if requested\n",
    "    out = None\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    detection_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Process every 5th frame to improve performance\n",
    "            if frame_count % 5 == 0:\n",
    "                # Process frame\n",
    "                results = integrated_system.process_frame(frame)\n",
    "                \n",
    "                # Check if anything was detected\n",
    "                if results['plates'] or results['faces']:\n",
    "                    detection_count += 1\n",
    "                    print(f\"Frame {frame_count}: Detected {len(results['plates'])} plates, {len(results['faces'])} faces\")\n",
    "                \n",
    "                # Draw detections\n",
    "                output_frame = integrated_system.draw_detections(frame, results)\n",
    "                \n",
    "                # Add frame number\n",
    "                cv2.putText(output_frame, f\"Frame: {frame_count}/{total_frames}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Save processed frame\n",
    "                if save_frames and (results['plates'] or results['faces']):\n",
    "                    frame_filename = f\"integrated_results/frame_{frame_count:06d}.jpg\"\n",
    "                    cv2.imwrite(frame_filename, output_frame)\n",
    "                \n",
    "                # Write to output video\n",
    "                if out is not None:\n",
    "                    out.write(output_frame)\n",
    "                \n",
    "                # Display progress\n",
    "                if frame_count % 100 == 0:\n",
    "                    progress = (frame_count / total_frames) * 100\n",
    "                    print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "            \n",
    "            else:\n",
    "                # Just write original frame if not processing\n",
    "                if out is not None:\n",
    "                    out.write(frame)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcessing interrupted...\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        if out is not None:\n",
    "            out.release()\n",
    "        \n",
    "        print(f\"\\nVideo processing completed!\")\n",
    "        print(f\"Total frames processed: {frame_count}\")\n",
    "        print(f\"Frames with detections: {detection_count}\")\n",
    "        \n",
    "        if output_path:\n",
    "            print(f\"Output video saved: {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# process_video_file(\"path/to/your/video.mp4\", \"output_video.mp4\", save_frames=True)\n",
    "print(\"To process a video file, call: process_video_file('path/to/video.mp4', 'output.mp4')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05391627",
   "metadata": {},
   "source": [
    "## 9. View Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a345884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_detection_results():\n",
    "    \"\"\"View and analyze detection results\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load combined results\n",
    "    csv_path = \"integrated_results/combined_detections.csv\"\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"No detection results found. Run some detections first.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        print(\"\\n=== DETECTION RESULTS SUMMARY ===\")\n",
    "        print(f\"Total detections: {len(df)}\")\n",
    "        \n",
    "        # Plate statistics\n",
    "        plates_detected = df[df['plate_text'] != ''].shape[0]\n",
    "        unique_plates = df[df['plate_text'] != '']['plate_text'].nunique()\n",
    "        print(f\"\\nLicense Plates:\")\n",
    "        print(f\"  Total detections: {plates_detected}\")\n",
    "        print(f\"  Unique plates: {unique_plates}\")\n",
    "        \n",
    "        if plates_detected > 0:\n",
    "            print(f\"  Average confidence: {df[df['plate_text'] != '']['plate_confidence'].mean():.3f}\")\n",
    "            print(\"\\nMost frequently detected plates:\")\n",
    "            plate_counts = df[df['plate_text'] != '']['plate_text'].value_counts()\n",
    "            for plate, count in plate_counts.head(5).items():\n",
    "                print(f\"    {plate}: {count} times\")\n",
    "        \n",
    "        # Face statistics\n",
    "        faces_detected = df[df['face_name'] != ''].shape[0]\n",
    "        unique_faces = df[df['face_name'] != '']['face_name'].nunique()\n",
    "        print(f\"\\nFaces:\")\n",
    "        print(f\"  Total detections: {faces_detected}\")\n",
    "        print(f\"  Unique faces: {unique_faces}\")\n",
    "        \n",
    "        if faces_detected > 0:\n",
    "            print(f\"  Average confidence: {df[df['face_name'] != '']['face_confidence'].mean():.3f}\")\n",
    "            print(\"\\nMost frequently detected faces:\")\n",
    "            face_counts = df[df['face_name'] != '']['face_name'].value_counts()\n",
    "            for face, count in face_counts.head(5).items():\n",
    "                print(f\"    {face}: {count} times\")\n",
    "        \n",
    "        # Recent detections\n",
    "        print(\"\\n=== RECENT DETECTIONS ===\")\n",
    "        recent = df.tail(10)\n",
    "        for _, row in recent.iterrows():\n",
    "            timestamp = row['timestamp']\n",
    "            plate = row['plate_text'] if row['plate_text'] else \"No plate\"\n",
    "            face = row['face_name'] if row['face_name'] else \"No face\"\n",
    "            print(f\"  {timestamp}: Plate={plate}, Face={face}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading results: {e}\")\n",
    "        return None\n",
    "\n",
    "# View results\n",
    "results_df = view_detection_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c051fb",
   "metadata": {},
   "source": [
    "## 10. System Configuration and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System configuration\n",
    "def configure_system():\n",
    "    \"\"\"Configure system parameters\"\"\"\n",
    "    config = {\n",
    "        'anpr': {\n",
    "            'confidence_threshold': 0.5,\n",
    "            'min_plate_width': 100,\n",
    "            'min_plate_height': 30,\n",
    "            'aspect_ratio_min': 2.0,\n",
    "            'aspect_ratio_max': 4.5\n",
    "        },\n",
    "        'frs': {\n",
    "            'recognition_threshold': 0.6,\n",
    "            'min_face_size': 30,\n",
    "            'scale_factor': 1.1,\n",
    "            'min_neighbors': 5\n",
    "        },\n",
    "        'processing': {\n",
    "            'save_detections': True,\n",
    "            'save_unknown_faces': False,\n",
    "            'process_every_nth_frame': 5,\n",
    "            'max_results_to_keep': 1000\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Current system configuration:\")\n",
    "    for category, settings in config.items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        for key, value in settings.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Display current configuration\n",
    "system_config = configure_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d97fb2",
   "metadata": {},
   "source": [
    "## 11. Quick Start Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1703b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quick_start_guide():\n",
    "    \"\"\"Print quick start guide\"\"\"\n",
    "    guide = \"\"\"\n",
    "🚀 QUICK START GUIDE - Indian ANPR + FRS System\n",
    "================================================\n",
    "\n",
    "1. ADD KNOWN FACES:\n",
    "   - Place face images in 'sample_faces' folder, OR\n",
    "   - Use webcam: capture_and_add_face(\"PersonName\")\n",
    "\n",
    "2. TEST WITH IMAGE:\n",
    "   test_sample_image(\"path/to/your/image.jpg\")\n",
    "\n",
    "3. REAL-TIME DETECTION:\n",
    "   run_realtime_detection()\n",
    "   (Press 'q' to quit)\n",
    "\n",
    "4. PROCESS VIDEO:\n",
    "   process_video_file(\"input.mp4\", \"output.mp4\")\n",
    "\n",
    "5. VIEW RESULTS:\n",
    "   view_detection_results()\n",
    "\n",
    "📁 OUTPUT FOLDERS:\n",
    "   - anpr_results/     : License plate detections\n",
    "   - face_results/     : Face recognition results  \n",
    "   - integrated_results/ : Combined ANPR + FRS results\n",
    "   - known_faces/      : Database of known faces\n",
    "\n",
    "📊 FEATURES:\n",
    "   ✅ Indian number plate format detection\n",
    "   ✅ EasyOCR for accurate text extraction\n",
    "   ✅ FaceNet-based facial recognition\n",
    "   ✅ Real-time processing from webcam\n",
    "   ✅ Video file processing\n",
    "   ✅ CSV logging of all detections\n",
    "   ✅ Image saving for verification\n",
    "\n",
    "🎯 OPTIMIZED FOR:\n",
    "   - Indian vehicle number plates (all formats)\n",
    "   - Multi-language support (Hindi, English)\n",
    "   - Various lighting conditions\n",
    "   - Real-time performance\n",
    "\"\"\"\n",
    "    print(guide)\n",
    "\n",
    "# Display quick start guide\n",
    "print_quick_start_guide()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
