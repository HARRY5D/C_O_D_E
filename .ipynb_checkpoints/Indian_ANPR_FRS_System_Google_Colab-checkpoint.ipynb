{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ad39eb",
   "metadata": {},
   "source": [
    "# Indian Vehicle Number Plate Recognition & Facial Recognition System\n",
    "## Google Colab Optimized Version\n",
    "\n",
    "üöÄ **Cloud-Ready ANPR + FRS System for Google Colab**\n",
    "\n",
    "A focused implementation combining:\n",
    "- **Automatic Number Plate Recognition (ANPR)** optimized for Indian number plates\n",
    "- **Facial Recognition System (FRS)** for person identification\n",
    "\n",
    "## ‚ú® Google Colab Features:\n",
    "- ‚òÅÔ∏è Cloud-optimized installation and setup\n",
    "- üìÅ Easy file upload and download\n",
    "- üé• Webcam integration for Colab\n",
    "- üìä Interactive visualization with matplotlib\n",
    "- üíæ Google Drive integration for data persistence\n",
    "- üîÑ Real-time processing with progress bars\n",
    "- üì± Mobile-friendly interface\n",
    "\n",
    "## üéØ Key Technologies:\n",
    "- EasyOCR for Indian number plate text extraction\n",
    "- face_recognition library (no TensorFlow dependency)\n",
    "- OpenCV for computer vision\n",
    "- Jupyter widgets for interactive uploads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08a31f",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 1. Environment Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833aa1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üöÄ Running in Google Colab!\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running in local environment\")\n",
    "\n",
    "# Install required packages optimized for Colab\n",
    "if IN_COLAB:\n",
    "    print(\"üì¶ Installing packages for Google Colab...\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1\n",
    "    !pip install -q opencv-python-headless easyocr face-recognition scikit-learn numpy matplotlib pillow\n",
    "    !pip install -q ipywidgets tqdm\n",
    "    \n",
    "    # Enable widgets extension for Colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "else:\n",
    "    !pip install opencv-python easyocr face-recognition scikit-learn numpy matplotlib pillow ipywidgets tqdm\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import face_recognition\n",
    "import threading\n",
    "import time\n",
    "import uuid\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Colab-specific imports\n",
    "if IN_COLAB:\n",
    "    from google.colab import files, drive\n",
    "    from google.colab.patches import cv2_imshow\n",
    "else:\n",
    "    # Fallback function for local environments\n",
    "    def cv2_imshow(img):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(\"üéØ Using face_recognition library (TensorFlow-free)\")\n",
    "print(f\"üåê Environment: {'Google Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac02db",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è 2. Google Drive Integration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Mount Google Drive for persistent storage\n",
    "if IN_COLAB:\n",
    "    mount_drive = input(\"Mount Google Drive for persistent storage? (y/n): \").lower().strip()\n",
    "    \n",
    "    if mount_drive == 'y':\n",
    "        try:\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "            \n",
    "            # Create working directory in Google Drive\n",
    "            work_dir = '/content/drive/MyDrive/ANPR_FRS_System'\n",
    "            os.makedirs(work_dir, exist_ok=True)\n",
    "            os.chdir(work_dir)\n",
    "            print(f\"üìÅ Working directory: {work_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error mounting Google Drive: {e}\")\n",
    "            print(\"üìÅ Using temporary Colab storage\")\n",
    "    else:\n",
    "        print(\"üìÅ Using temporary Colab storage (data will be lost after session)\")\n",
    "else:\n",
    "    print(\"üíª Running locally - using current directory\")\n",
    "\n",
    "# Create necessary directories\n",
    "directories = ['anpr_results', 'face_results', 'integrated_results', 'known_faces', 'uploads']\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "print(\"üìÇ Created necessary directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b589f",
   "metadata": {},
   "source": [
    "## üöó 3. Indian Number Plate Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianANPR:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Indian ANPR system with EasyOCR\"\"\"\n",
    "        print(\"üîß Initializing EasyOCR for Indian number plates...\")\n",
    "        \n",
    "        # Initialize EasyOCR with English language\n",
    "        self.reader = easyocr.Reader(['en'], gpu=True if IN_COLAB else False)\n",
    "        \n",
    "        # Indian number plate patterns\n",
    "        self.indian_patterns = [\n",
    "            r'[A-Z]{2}\\s?[0-9]{1,2}\\s?[A-Z]{1,2}\\s?[0-9]{1,4}',  # Standard: XX 00 XX 0000\n",
    "            r'[A-Z]{2}[0-9]{1,2}[A-Z]{1,2}[0-9]{1,4}',           # No spaces\n",
    "            r'[0-9]{2}\\s?BH\\s?[0-9]{4}\\s?[A-Z]{2}',              # Bharat series\n",
    "            r'[0-9]{2}BH[0-9]{4}[A-Z]{2}',                        # Bharat no spaces\n",
    "        ]\n",
    "        \n",
    "        print(\"‚úÖ Indian ANPR system initialized!\")\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply bilateral filter to reduce noise while keeping edges sharp\n",
    "        filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "        \n",
    "        # Find edges\n",
    "        edged = cv2.Canny(filtered, 30, 200)\n",
    "        \n",
    "        return gray, filtered, edged\n",
    "    \n",
    "    def find_license_plate_contours(self, edged_image):\n",
    "        \"\"\"Find potential license plate contours\"\"\"\n",
    "        contours, _ = cv2.findContours(edged_image.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "        \n",
    "        license_plate_contours = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate contour\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.018 * perimeter, True)\n",
    "            \n",
    "            # Check if contour has 4 corners (rectangle-like)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h\n",
    "                \n",
    "                # Indian license plates typically have aspect ratio between 2:1 and 4:1\n",
    "                if 2.0 <= aspect_ratio <= 4.5 and w > 100 and h > 30:\n",
    "                    license_plate_contours.append((x, y, w, h, contour))\n",
    "        \n",
    "        return license_plate_contours\n",
    "    \n",
    "    def extract_text_from_roi(self, image, roi):\n",
    "        \"\"\"Extract text from Region of Interest using EasyOCR\"\"\"\n",
    "        x, y, w, h = roi[:4]\n",
    "        plate_region = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize for better OCR\n",
    "        plate_region = cv2.resize(plate_region, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Apply additional preprocessing\n",
    "        plate_gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n",
    "        plate_thresh = cv2.threshold(plate_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        \n",
    "        # Use EasyOCR to extract text\n",
    "        try:\n",
    "            results = self.reader.readtext(plate_thresh)\n",
    "            if results:\n",
    "                # Combine all detected text\n",
    "                text = ' '.join([result[1] for result in results if result[2] > 0.5])\n",
    "                return self.validate_indian_plate(text), plate_region\n",
    "        except Exception as e:\n",
    "            print(f\"OCR Error: {e}\")\n",
    "        \n",
    "        return None, plate_region\n",
    "    \n",
    "    def validate_indian_plate(self, text):\n",
    "        \"\"\"Validate if text matches Indian number plate patterns\"\"\"\n",
    "        if not text:\n",
    "            return None\n",
    "            \n",
    "        # Clean the text\n",
    "        cleaned_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "        \n",
    "        # Check against Indian patterns\n",
    "        for pattern in self.indian_patterns:\n",
    "            if re.match(pattern, text.upper()):\n",
    "                return text.upper()\n",
    "            if re.match(pattern, cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        # If no exact match, check if it looks like a valid plate\n",
    "        if len(cleaned_text) >= 6 and len(cleaned_text) <= 10:\n",
    "            # Basic validation: should have letters and numbers\n",
    "            if re.search(r'[A-Z]', cleaned_text) and re.search(r'[0-9]', cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def process_image(self, image):\n",
    "        \"\"\"Process image and detect Indian number plates\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Preprocess image\n",
    "        gray, filtered, edged = self.preprocess_image(image)\n",
    "        \n",
    "        # Find potential license plate contours\n",
    "        plate_contours = self.find_license_plate_contours(edged)\n",
    "        \n",
    "        # Process each potential plate\n",
    "        for roi in plate_contours:\n",
    "            plate_text, plate_image = self.extract_text_from_roi(image, roi)\n",
    "            \n",
    "            if plate_text:\n",
    "                results.append({\n",
    "                    'text': plate_text,\n",
    "                    'bbox': roi[:4],\n",
    "                    'confidence': 0.8,  # Placeholder confidence\n",
    "                    'plate_image': plate_image\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_detection(self, plate_image, plate_text, confidence, timestamp):\n",
    "        \"\"\"Save plate detection with timestamp\"\"\"\n",
    "        filename = f\"anpr_results/plate_{timestamp}_{plate_text.replace(' ', '_')}.jpg\"\n",
    "        cv2.imwrite(filename, plate_image)\n",
    "        return filename\n",
    "\n",
    "# Initialize ANPR system\n",
    "anpr = IndianANPR()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f14258",
   "metadata": {},
   "source": [
    "## üë§ 4. Facial Recognition System (TensorFlow-Free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize facial recognition system using face_recognition library\"\"\"\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "        \n",
    "        print(\"üë§ Facial Recognition System initialized with face_recognition library\")\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces in image using face_recognition library\"\"\"\n",
    "        # Convert BGR to RGB (face_recognition uses RGB)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face locations\n",
    "        face_locations = face_recognition.face_locations(rgb_image)\n",
    "        \n",
    "        # Convert to (x, y, w, h) format for consistency with OpenCV\n",
    "        faces = []\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            faces.append((left, top, right - left, bottom - top))\n",
    "        \n",
    "        return faces\n",
    "    \n",
    "    def extract_face_encoding(self, image, face_location=None):\n",
    "        \"\"\"Extract face encoding using face_recognition library\"\"\"\n",
    "        # Convert BGR to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if face_location is not None:\n",
    "            # Convert (x, y, w, h) to (top, right, bottom, left)\n",
    "            x, y, w, h = face_location\n",
    "            face_location = (y, x + w, y + h, x)\n",
    "            face_locations = [face_location]\n",
    "        else:\n",
    "            face_locations = face_recognition.face_locations(rgb_image)\n",
    "        \n",
    "        if not face_locations:\n",
    "            return None\n",
    "        \n",
    "        # Get face encodings\n",
    "        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "        \n",
    "        if face_encodings:\n",
    "            return face_encodings[0]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def add_known_face(self, image, name):\n",
    "        \"\"\"Add a known face to the database\"\"\"\n",
    "        faces = self.detect_faces(image)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            print(f\"‚ùå No face detected for {name}\")\n",
    "            return False\n",
    "        \n",
    "        if len(faces) > 1:\n",
    "            print(f\"‚ö†Ô∏è Multiple faces detected for {name}. Using the largest one.\")\n",
    "        \n",
    "        # Use the largest face\n",
    "        face = max(faces, key=lambda x: x[2] * x[3])\n",
    "        x, y, w, h = face\n",
    "        face_image = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Extract face encoding\n",
    "        encoding = self.extract_face_encoding(image, face)\n",
    "        \n",
    "        if encoding is None:\n",
    "            print(f\"‚ùå Could not encode face for {name}\")\n",
    "            return False\n",
    "        \n",
    "        # Store encoding and name\n",
    "        self.known_face_encodings.append(encoding)\n",
    "        self.known_face_names.append(name)\n",
    "        \n",
    "        # Save face image\n",
    "        face_filename = f\"known_faces/{name}_{len(self.known_face_encodings)}.jpg\"\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "        \n",
    "        print(f\"‚úÖ Added {name} to known faces database\")\n",
    "        return True\n",
    "    \n",
    "    def recognize_faces(self, image, tolerance=0.6):\n",
    "        \"\"\"Recognize faces in image\"\"\"\n",
    "        if len(self.known_face_encodings) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face locations and encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_image)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, face_encoding in enumerate(face_encodings):\n",
    "            # Compare with known faces\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding, tolerance)\n",
    "            \n",
    "            name = \"Unknown\"\n",
    "            confidence = 0.0\n",
    "            \n",
    "            if True in matches:\n",
    "                # Find the best match\n",
    "                best_match_index = np.argmin(distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = self.known_face_names[best_match_index]\n",
    "                    # Convert distance to confidence (0-1 scale)\n",
    "                    confidence = max(0, 1 - distances[best_match_index])\n",
    "            \n",
    "            # Convert face location to (x, y, w, h) format\n",
    "            top, right, bottom, left = face_locations[i]\n",
    "            x, y, w, h = left, top, right - left, bottom - top\n",
    "            \n",
    "            # Extract face image\n",
    "            face_image = image[y:y+h, x:x+w]\n",
    "            \n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'confidence': confidence,\n",
    "                'bbox': (x, y, w, h),\n",
    "                'face_image': face_image\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_detection(self, face_image, name, confidence, timestamp):\n",
    "        \"\"\"Save face detection with timestamp\"\"\"\n",
    "        filename = f\"face_results/face_{timestamp}_{name}_{confidence:.2f}.jpg\"\n",
    "        cv2.imwrite(filename, face_image)\n",
    "        return filename\n",
    "    \n",
    "    def save_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Save known faces database to file\"\"\"\n",
    "        database = {\n",
    "            'encodings': self.known_face_encodings,\n",
    "            'names': self.known_face_names\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(database, f)\n",
    "        \n",
    "        print(f\"üíæ Face database saved to {filename}\")\n",
    "    \n",
    "    def load_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Load known faces database from file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                database = pickle.load(f)\n",
    "            \n",
    "            self.known_face_encodings = database['encodings']\n",
    "            self.known_face_names = database['names']\n",
    "            \n",
    "            print(f\"üìÇ Face database loaded from {filename}\")\n",
    "            print(f\"üë• Loaded {len(self.known_face_names)} known faces\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"üìÑ Database file {filename} not found\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading database: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize FRS system\n",
    "frs = FacialRecognitionSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd038e8b",
   "metadata": {},
   "source": [
    "## üîó 5. Integrated ANPR + FRS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedANPR_FRS:\n",
    "    def __init__(self, anpr_system, frs_system):\n",
    "        \"\"\"Initialize integrated ANPR + FRS system\"\"\"\n",
    "        self.anpr = anpr_system\n",
    "        self.frs = frs_system\n",
    "        \n",
    "        # Initialize CSV file with headers\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        if not os.path.exists(csv_filename):\n",
    "            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    'timestamp', 'plate_text', 'plate_confidence',\n",
    "                    'face_name', 'face_confidence', 'plate_image_path', 'face_image_path'\n",
    "                ])\n",
    "        \n",
    "        print(\"üîó Integrated ANPR + FRS system initialized!\")\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for both ANPR and FRS\"\"\"\n",
    "        results = {\n",
    "            'plates': [],\n",
    "            'faces': []\n",
    "        }\n",
    "        \n",
    "        # Process ANPR\n",
    "        try:\n",
    "            plate_results = self.anpr.process_image(frame)\n",
    "            results['plates'] = plate_results\n",
    "        except Exception as e:\n",
    "            print(f\"üöó ANPR Error: {e}\")\n",
    "        \n",
    "        # Process FRS\n",
    "        try:\n",
    "            face_results = self.frs.recognize_faces(frame)\n",
    "            results['faces'] = face_results\n",
    "        except Exception as e:\n",
    "            print(f\"üë§ FRS Error: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def log_detections(self, results):\n",
    "        \"\"\"Log detection results to CSV and save images\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        \n",
    "        # Default values\n",
    "        plate_text = \"\"\n",
    "        plate_confidence = 0.0\n",
    "        face_name = \"\"\n",
    "        face_confidence = 0.0\n",
    "        plate_image = \"\"\n",
    "        face_image = \"\"\n",
    "        \n",
    "        # Process plate detections\n",
    "        if results['plates']:\n",
    "            best_plate = max(results['plates'], key=lambda x: x['confidence'])\n",
    "            plate_text = best_plate['text']\n",
    "            plate_confidence = best_plate['confidence']\n",
    "            plate_image = self.anpr.save_detection(\n",
    "                best_plate['plate_image'], plate_text, plate_confidence, timestamp\n",
    "            )\n",
    "        \n",
    "        # Process face detections\n",
    "        if results['faces']:\n",
    "            best_face = max(results['faces'], key=lambda x: x['confidence'])\n",
    "            face_name = best_face['name']\n",
    "            face_confidence = best_face['confidence']\n",
    "            face_image = self.frs.save_detection(\n",
    "                best_face['face_image'], face_name, face_confidence, timestamp\n",
    "            )\n",
    "        \n",
    "        # Save to combined CSV\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp, plate_text, plate_confidence,\n",
    "                face_name, face_confidence, plate_image, face_image\n",
    "            ])\n",
    "    \n",
    "    def draw_detections(self, frame, results):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Draw license plates\n",
    "        for plate in results['plates']:\n",
    "            x, y, w, h = plate['bbox']\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(output_frame, f\"Plate: {plate['text']}\", \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw faces\n",
    "        for face in results['faces']:\n",
    "            x, y, w, h = face['bbox']\n",
    "            color = (0, 255, 255) if face['name'] != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            label = f\"{face['name']} ({face['confidence']:.2f})\"\n",
    "            cv2.putText(output_frame, label, \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        return output_frame\n",
    "\n",
    "# Initialize integrated system\n",
    "integrated_system = IntegratedANPR_FRS(anpr, frs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ef047",
   "metadata": {},
   "source": [
    "## üìÅ 6. File Upload and Management (Colab Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload widget for Google Colab\n",
    "def create_upload_widget():\n",
    "    \"\"\"Create an interactive file upload widget\"\"\"\n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.jpg,.jpeg,.png,.mp4,.avi,.mov',  # Accept images and videos\n",
    "        multiple=True,\n",
    "        description='Upload Files',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def on_upload_change(change):\n",
    "        if change['new']:\n",
    "            for filename, file_info in upload_widget.value.items():\n",
    "                # Save uploaded file\n",
    "                file_path = f\"uploads/{filename}\"\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    f.write(file_info['content'])\n",
    "                print(f\"‚úÖ Uploaded: {filename}\")\n",
    "    \n",
    "    upload_widget.observe(on_upload_change, names='value')\n",
    "    return upload_widget\n",
    "\n",
    "# Alternative: Direct file upload for Colab\n",
    "def upload_files():\n",
    "    \"\"\"Upload files using Colab's file upload\"\"\"\n",
    "    if IN_COLAB:\n",
    "        print(\"üìÅ Select files to upload (images/videos):\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        uploaded_files = []\n",
    "        for filename, content in uploaded.items():\n",
    "            file_path = f\"uploads/{filename}\"\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "            uploaded_files.append(file_path)\n",
    "            print(f\"‚úÖ Saved: {file_path}\")\n",
    "        \n",
    "        return uploaded_files\n",
    "    else:\n",
    "        print(\"üíª Running locally - use file browser to select files\")\n",
    "        return []\n",
    "\n",
    "# Function to load sample images from URLs (for demo)\n",
    "def load_sample_images():\n",
    "    \"\"\"Load sample images for demonstration\"\"\"\n",
    "    import urllib.request\n",
    "    \n",
    "    sample_urls = {\n",
    "        \"indian_car.jpg\": \"https://via.placeholder.com/800x600/4169E1/FFFFFF?text=Indian+Car+Sample\",\n",
    "        \"person_sample.jpg\": \"https://via.placeholder.com/600x600/FF6347/FFFFFF?text=Person+Sample\"\n",
    "    }\n",
    "    \n",
    "    print(\"üì∏ Loading sample images for demonstration...\")\n",
    "    for filename, url in sample_urls.items():\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, f\"uploads/{filename}\")\n",
    "            print(f\"‚úÖ Downloaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading {filename}: {e}\")\n",
    "\n",
    "# Display upload widget\n",
    "print(\"üì§ File Upload Options:\")\n",
    "print(\"1. Use the widget below\")\n",
    "print(\"2. Call upload_files() function\")\n",
    "print(\"3. Call load_sample_images() for demo\")\n",
    "\n",
    "upload_widget = create_upload_widget()\n",
    "display(upload_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05d7be",
   "metadata": {},
   "source": [
    "## üë• 7. Face Database Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive face addition system\n",
    "def add_face_from_upload():\n",
    "    \"\"\"Add faces to database from uploaded images\"\"\"\n",
    "    upload_dir = \"uploads\"\n",
    "    known_faces_added = 0\n",
    "    \n",
    "    if not os.path.exists(upload_dir) or not os.listdir(upload_dir):\n",
    "        print(\"üìÅ No uploaded files found. Please upload images first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üë• Processing uploaded images for face recognition...\")\n",
    "    \n",
    "    for filename in os.listdir(upload_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(upload_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is not None:\n",
    "                # Use filename (without extension) as person name\n",
    "                person_name = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Ask user for confirmation\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Add '{person_name}' to face database?\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                if IN_COLAB:\n",
    "                    response = input(f\"Add '{person_name}' to database? (y/n): \").lower().strip()\n",
    "                else:\n",
    "                    response = 'y'  # Auto-accept in local environment\n",
    "                \n",
    "                if response == 'y':\n",
    "                    if frs.add_known_face(image, person_name):\n",
    "                        known_faces_added += 1\n",
    "                        print(f\"‚úÖ Added {person_name} to face database\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Could not add {person_name} to database\")\n",
    "    \n",
    "    if known_faces_added > 0:\n",
    "        frs.save_database()\n",
    "        print(f\"üíæ Saved {known_faces_added} faces to database\")\n",
    "    else:\n",
    "        print(\"‚ùå No faces were added to the database\")\n",
    "\n",
    "# Function to create a face from webcam (Colab compatible)\n",
    "def create_webcam_interface():\n",
    "    \"\"\"Create webcam interface for adding faces\"\"\"\n",
    "    if IN_COLAB:\n",
    "        from google.colab import drive\n",
    "        from IPython.display import Javascript, display\n",
    "        \n",
    "        print(\"üì∑ Webcam interface for Google Colab\")\n",
    "        print(\"Note: Due to Colab limitations, please upload face images instead\")\n",
    "        print(\"Or use the mobile camera to take photos and upload them\")\n",
    "        \n",
    "        # JavaScript code for camera access in Colab\n",
    "        js_code = \"\"\"\n",
    "        async function takePicture() {\n",
    "            const video = document.createElement('video');\n",
    "            const canvas = document.createElement('canvas');\n",
    "            const ctx = canvas.getContext('2d');\n",
    "            \n",
    "            try {\n",
    "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "                video.srcObject = stream;\n",
    "                video.play();\n",
    "                \n",
    "                video.addEventListener('loadedmetadata', () => {\n",
    "                    canvas.width = video.videoWidth;\n",
    "                    canvas.height = video.videoHeight;\n",
    "                    ctx.drawImage(video, 0, 0);\n",
    "                    \n",
    "                    canvas.toBlob((blob) => {\n",
    "                        const url = URL.createObjectURL(blob);\n",
    "                        const a = document.createElement('a');\n",
    "                        a.href = url;\n",
    "                        a.download = 'captured_face.jpg';\n",
    "                        a.click();\n",
    "                    });\n",
    "                    \n",
    "                    stream.getTracks().forEach(track => track.stop());\n",
    "                });\n",
    "            } catch (err) {\n",
    "                console.error('Error accessing camera:', err);\n",
    "                alert('Camera access denied or not available');\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        takePicture();\n",
    "        \"\"\"\n",
    "        \n",
    "        display(Javascript(js_code))\n",
    "    else:\n",
    "        print(\"üíª Local environment - use OpenCV webcam capture\")\n",
    "\n",
    "# Load existing database\n",
    "frs.load_database()\n",
    "\n",
    "# Display current face database status\n",
    "print(f\"üë• Current face database: {len(frs.known_face_names)} known faces\")\n",
    "if frs.known_face_names:\n",
    "    print(\"Known faces:\", \", \".join(frs.known_face_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564cf9f",
   "metadata": {},
   "source": [
    "## üß™ 8. Testing and Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635679b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_uploaded_images():\n",
    "    \"\"\"Test the system with uploaded images\"\"\"\n",
    "    upload_dir = \"uploads\"\n",
    "    \n",
    "    if not os.path.exists(upload_dir) or not os.listdir(upload_dir):\n",
    "        print(\"üìÅ No uploaded files found. Please upload images first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üß™ Testing uploaded images...\")\n",
    "    \n",
    "    for filename in os.listdir(upload_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(upload_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is not None:\n",
    "                print(f\"\\nüì∏ Processing: {filename}\")\n",
    "                \n",
    "                # Process with integrated system\n",
    "                results = integrated_system.process_frame(image)\n",
    "                \n",
    "                # Draw detections\n",
    "                output_image = integrated_system.draw_detections(image, results)\n",
    "                \n",
    "                # Log detections\n",
    "                integrated_system.log_detections(results)\n",
    "                \n",
    "                # Display results\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "                \n",
    "                # Original image\n",
    "                axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                axes[0].set_title(f'Original: {filename}')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                # Processed image\n",
    "                axes[1].imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "                axes[1].set_title('Detections')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Print results\n",
    "                print(\"üîç Detection Results:\")\n",
    "                print(f\"  üöó License Plates: {len(results['plates'])}\")\n",
    "                for i, plate in enumerate(results['plates']):\n",
    "                    print(f\"    Plate {i+1}: {plate['text']} (Confidence: {plate['confidence']:.2f})\")\n",
    "                \n",
    "                print(f\"  üë§ Faces: {len(results['faces'])}\")\n",
    "                for i, face in enumerate(results['faces']):\n",
    "                    print(f\"    Face {i+1}: {face['name']} (Confidence: {face['confidence']:.2f})\")\n",
    "\n",
    "def process_video_colab(video_path, sample_frames=30):\n",
    "    \"\"\"Process video file optimized for Colab\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"‚ùå Video file not found: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error: Could not open video file: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"üé• Processing video: {video_path}\")\n",
    "    print(f\"üìä Properties: {fps} FPS, {total_frames} frames\")\n",
    "    print(f\"‚ö° Processing every {total_frames//sample_frames} frames for speed\")\n",
    "    \n",
    "    frame_interval = max(1, total_frames // sample_frames)\n",
    "    detection_count = 0\n",
    "    processed_frames = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(total=sample_frames, desc=\"Processing video\")\n",
    "    \n",
    "    for frame_num in range(0, total_frames, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process frame\n",
    "        results = integrated_system.process_frame(frame)\n",
    "        \n",
    "        # Log significant detections\n",
    "        if results['plates'] or (results['faces'] and \n",
    "                               any(face['name'] != 'Unknown' for face in results['faces'])):\n",
    "            integrated_system.log_detections(results)\n",
    "            detection_count += 1\n",
    "            \n",
    "            # Show frame with detections\n",
    "            if detection_count <= 5:  # Show first 5 detections\n",
    "                output_frame = integrated_system.draw_detections(frame, results)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Detection {detection_count} - Frame {frame_num}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "        \n",
    "        processed_frames += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Video processing completed!\")\n",
    "    print(f\"üìä Processed {processed_frames} frames\")\n",
    "    print(f\"üéØ Found {detection_count} significant detections\")\n",
    "\n",
    "# Create buttons for easy testing\n",
    "test_button = widgets.Button(\n",
    "    description='üß™ Test Uploaded Images',\n",
    "    style={'button_color': 'lightblue'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "add_faces_button = widgets.Button(\n",
    "    description='üë• Add Faces from Images',\n",
    "    style={'button_color': 'lightgreen'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "def on_test_click(b):\n",
    "    clear_output(wait=True)\n",
    "    test_uploaded_images()\n",
    "\n",
    "def on_add_faces_click(b):\n",
    "    clear_output(wait=True)\n",
    "    add_face_from_upload()\n",
    "\n",
    "test_button.on_click(on_test_click)\n",
    "add_faces_button.on_click(on_add_faces_click)\n",
    "\n",
    "button_box = widgets.HBox([test_button, add_faces_button])\n",
    "display(button_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ae7c2",
   "metadata": {},
   "source": [
    "## üìä 9. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_detection_results():\n",
    "    \"\"\"View and analyze detection results with enhanced visualization\"\"\"\n",
    "    csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"‚ùå No detection results found.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"üìä DETECTION RESULTS ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìà Total detections: {len(df)}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Plate statistics\n",
    "        plates_detected = df[df['plate_text'] != ''].shape[0]\n",
    "        unique_plates = df[df['plate_text'] != '']['plate_text'].nunique()\n",
    "        \n",
    "        print(f\"\\nüöó License Plates:\")\n",
    "        print(f\"  Total detections: {plates_detected}\")\n",
    "        print(f\"  Unique plates: {unique_plates}\")\n",
    "        \n",
    "        if plates_detected > 0:\n",
    "            avg_plate_conf = df[df['plate_text'] != '']['plate_confidence'].mean()\n",
    "            print(f\"  Average confidence: {avg_plate_conf:.3f}\")\n",
    "            \n",
    "            # Plot plate detections over time\n",
    "            plate_data = df[df['plate_text'] != ''].copy()\n",
    "            plate_data['timestamp'] = pd.to_datetime(plate_data['timestamp'], format='%Y%m%d_%H%M%S_%f')\n",
    "            plate_counts = plate_data.groupby(plate_data['timestamp'].dt.hour).size()\n",
    "            \n",
    "            axes[0, 0].bar(plate_counts.index, plate_counts.values, color='green', alpha=0.7)\n",
    "            axes[0, 0].set_title('Plate Detections by Hour')\n",
    "            axes[0, 0].set_xlabel('Hour')\n",
    "            axes[0, 0].set_ylabel('Count')\n",
    "            \n",
    "            # Most frequent plates\n",
    "            top_plates = df[df['plate_text'] != '']['plate_text'].value_counts().head(5)\n",
    "            axes[0, 1].barh(range(len(top_plates)), top_plates.values, color='blue', alpha=0.7)\n",
    "            axes[0, 1].set_yticks(range(len(top_plates)))\n",
    "            axes[0, 1].set_yticklabels(top_plates.index)\n",
    "            axes[0, 1].set_title('Most Detected Plates')\n",
    "            axes[0, 1].set_xlabel('Detection Count')\n",
    "        \n",
    "        # Face statistics\n",
    "        faces_detected = df[df['face_name'] != ''].shape[0]\n",
    "        unique_faces = df[df['face_name'] != '']['face_name'].nunique()\n",
    "        \n",
    "        print(f\"\\nüë§ Faces:\")\n",
    "        print(f\"  Total detections: {faces_detected}\")\n",
    "        print(f\"  Unique faces: {unique_faces}\")\n",
    "        \n",
    "        if faces_detected > 0:\n",
    "            avg_face_conf = df[df['face_name'] != '']['face_confidence'].mean()\n",
    "            print(f\"  Average confidence: {avg_face_conf:.3f}\")\n",
    "            \n",
    "            # Plot face detections\n",
    "            face_data = df[df['face_name'] != ''].copy()\n",
    "            top_faces = face_data['face_name'].value_counts().head(5)\n",
    "            \n",
    "            axes[1, 0].pie(top_faces.values, labels=top_faces.index, autopct='%1.1f%%', startangle=90)\n",
    "            axes[1, 0].set_title('Face Recognition Distribution')\n",
    "            \n",
    "            # Confidence distribution\n",
    "            axes[1, 1].hist(face_data['face_confidence'], bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "            axes[1, 1].set_title('Face Recognition Confidence Distribution')\n",
    "            axes[1, 1].set_xlabel('Confidence')\n",
    "            axes[1, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Recent detections\n",
    "        print(\"\\nüïí RECENT DETECTIONS\")\n",
    "        print(\"-\" * 30)\n",
    "        recent = df.tail(10)\n",
    "        for _, row in recent.iterrows():\n",
    "            timestamp = row['timestamp']\n",
    "            plate = row['plate_text'] if row['plate_text'] else \"No plate\"\n",
    "            face = row['face_name'] if row['face_name'] else \"No face\"\n",
    "            print(f\"  {timestamp}: üöó {plate} | üë§ {face}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading results: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_results():\n",
    "    \"\"\"Download results for local analysis\"\"\"\n",
    "    if IN_COLAB:\n",
    "        print(\"üì• Downloading results...\")\n",
    "        \n",
    "        # Create a zip file with all results\n",
    "        import zipfile\n",
    "        \n",
    "        zip_filename = \"ANPR_FRS_Results.zip\"\n",
    "        \n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "            # Add CSV file\n",
    "            if os.path.exists(\"integrated_results/combined_detections.csv\"):\n",
    "                zipf.write(\"integrated_results/combined_detections.csv\", \"combined_detections.csv\")\n",
    "            \n",
    "            # Add result images\n",
    "            for folder in ['anpr_results', 'face_results', 'integrated_results']:\n",
    "                if os.path.exists(folder):\n",
    "                    for filename in os.listdir(folder):\n",
    "                        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            zipf.write(os.path.join(folder, filename), f\"{folder}/{filename}\")\n",
    "        \n",
    "        files.download(zip_filename)\n",
    "        print(f\"‚úÖ Downloaded: {zip_filename}\")\n",
    "    else:\n",
    "        print(\"üíª Running locally - files are already saved in current directory\")\n",
    "\n",
    "# Create analysis button\n",
    "analysis_button = widgets.Button(\n",
    "    description='üìä Analyze Results',\n",
    "    style={'button_color': 'yellow'},\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='üì• Download Results',\n",
    "    style={'button_color': 'orange'},\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "def on_analysis_click(b):\n",
    "    view_detection_results()\n",
    "\n",
    "def on_download_click(b):\n",
    "    download_results()\n",
    "\n",
    "analysis_button.on_click(on_analysis_click)\n",
    "download_button.on_click(on_download_click)\n",
    "\n",
    "analysis_box = widgets.HBox([analysis_button, download_button])\n",
    "display(analysis_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf1466",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 10. System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive system configuration\n",
    "def create_config_interface():\n",
    "    \"\"\"Create interactive configuration interface\"\"\"\n",
    "    \n",
    "    # ANPR Configuration\n",
    "    anpr_confidence = widgets.FloatSlider(\n",
    "        value=0.5,\n",
    "        min=0.1,\n",
    "        max=1.0,\n",
    "        step=0.1,\n",
    "        description='ANPR Confidence:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # FRS Configuration\n",
    "    frs_tolerance = widgets.FloatSlider(\n",
    "        value=0.6,\n",
    "        min=0.3,\n",
    "        max=0.9,\n",
    "        step=0.1,\n",
    "        description='Face Recognition Tolerance:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Processing Configuration\n",
    "    process_frames = widgets.IntSlider(\n",
    "        value=5,\n",
    "        min=1,\n",
    "        max=20,\n",
    "        step=1,\n",
    "        description='Process Every N Frames:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # GPU Usage\n",
    "    use_gpu = widgets.Checkbox(\n",
    "        value=IN_COLAB,\n",
    "        description='Use GPU (if available)',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Save configuration\n",
    "    save_config_button = widgets.Button(\n",
    "        description='üíæ Save Configuration',\n",
    "        style={'button_color': 'lightgreen'}\n",
    "    )\n",
    "    \n",
    "    def save_configuration(b):\n",
    "        config = {\n",
    "            'anpr_confidence': anpr_confidence.value,\n",
    "            'frs_tolerance': frs_tolerance.value,\n",
    "            'process_frames': process_frames.value,\n",
    "            'use_gpu': use_gpu.value\n",
    "        }\n",
    "        \n",
    "        with open('system_config.pkl', 'wb') as f:\n",
    "            pickle.dump(config, f)\n",
    "        \n",
    "        print(\"‚úÖ Configuration saved!\")\n",
    "        print(f\"üìä ANPR Confidence: {config['anpr_confidence']}\")\n",
    "        print(f\"üë§ FRS Tolerance: {config['frs_tolerance']}\")\n",
    "        print(f\"‚ö° Process Every {config['process_frames']} Frames\")\n",
    "        print(f\"üñ•Ô∏è GPU Usage: {config['use_gpu']}\")\n",
    "    \n",
    "    save_config_button.on_click(save_configuration)\n",
    "    \n",
    "    config_box = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üîß System Configuration</h3>\"),\n",
    "        anpr_confidence,\n",
    "        frs_tolerance,\n",
    "        process_frames,\n",
    "        use_gpu,\n",
    "        save_config_button\n",
    "    ])\n",
    "    \n",
    "    return config_box\n",
    "\n",
    "# Display configuration interface\n",
    "config_interface = create_config_interface()\n",
    "display(config_interface)\n",
    "\n",
    "# Load existing configuration if available\n",
    "try:\n",
    "    with open('system_config.pkl', 'rb') as f:\n",
    "        saved_config = pickle.load(f)\n",
    "    print(\"üìÇ Loaded saved configuration\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚öôÔ∏è Using default configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca319e",
   "metadata": {},
   "source": [
    "## üöÄ 11. Quick Start Guide and Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21952ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_colab_quick_start_guide():\n",
    "    \"\"\"Print comprehensive quick start guide for Google Colab\"\"\"\n",
    "    \n",
    "    guide_html = \"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                padding: 20px; border-radius: 10px; color: white; font-family: Arial;\">\n",
    "        <h2>üöÄ QUICK START GUIDE - Google Colab ANPR + FRS System</h2>\n",
    "        \n",
    "        <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "            <h3>üìã Step-by-Step Instructions:</h3>\n",
    "            <ol style=\"line-height: 1.8;\">\n",
    "                <li><strong>üîß Setup Complete:</strong> All packages are installed and systems initialized</li>\n",
    "                <li><strong>üìÅ Upload Images:</strong> Use the file upload widget or call <code>upload_files()</code></li>\n",
    "                <li><strong>üë• Add Known Faces:</strong> Click \"Add Faces from Images\" button</li>\n",
    "                <li><strong>üß™ Test System:</strong> Click \"Test Uploaded Images\" button</li>\n",
    "                <li><strong>üìä View Results:</strong> Click \"Analyze Results\" for detailed analysis</li>\n",
    "                <li><strong>üì• Download:</strong> Click \"Download Results\" to save your data</li>\n",
    "            </ol>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "            <h3>üìÅ Supported File Formats:</h3>\n",
    "            <ul style=\"line-height: 1.6;\">\n",
    "                <li><strong>Images:</strong> .jpg, .jpeg, .png</li>\n",
    "                <li><strong>Videos:</strong> .mp4, .avi, .mov</li>\n",
    "                <li><strong>Faces:</strong> Clear frontal face images work best</li>\n",
    "                <li><strong>Plates:</strong> Indian format number plates</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "            <h3>üéØ Key Features:</h3>\n",
    "            <ul style=\"line-height: 1.6;\">\n",
    "                <li>‚úÖ <strong>No TensorFlow:</strong> Uses face_recognition library</li>\n",
    "                <li>‚úÖ <strong>Indian ANPR:</strong> Optimized for Indian number plates</li>\n",
    "                <li>‚úÖ <strong>Cloud Storage:</strong> Optional Google Drive integration</li>\n",
    "                <li>‚úÖ <strong>Interactive:</strong> Jupyter widgets for easy use</li>\n",
    "                <li>‚úÖ <strong>Visualization:</strong> Real-time results display</li>\n",
    "                <li>‚úÖ <strong>Export:</strong> Download all results as ZIP</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "            <h3>üí° Pro Tips:</h3>\n",
    "            <ul style=\"line-height: 1.6;\">\n",
    "                <li><strong>Face Quality:</strong> Use clear, well-lit face images</li>\n",
    "                <li><strong>Plate Clarity:</strong> Ensure number plates are clearly visible</li>\n",
    "                <li><strong>Processing Speed:</strong> Adjust frame processing in configuration</li>\n",
    "                <li><strong>Storage:</strong> Mount Google Drive for persistent data</li>\n",
    "                <li><strong>GPU:</strong> Colab provides free GPU acceleration</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(guide_html))\n",
    "\n",
    "# Demo function\n",
    "def run_demo():\n",
    "    \"\"\"Run a comprehensive demo of the system\"\"\"\n",
    "    print(\"üé¨ Starting System Demo...\")\n",
    "    \n",
    "    # Check if we have any uploaded files\n",
    "    if os.path.exists(\"uploads\") and os.listdir(\"uploads\"):\n",
    "        print(\"‚úÖ Found uploaded files - running live demo\")\n",
    "        test_uploaded_images()\n",
    "    else:\n",
    "        print(\"üì∏ No uploaded files found - loading sample data\")\n",
    "        load_sample_images()\n",
    "        \n",
    "        # Add a sample face\n",
    "        sample_face_data = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)\n",
    "        sample_face_path = \"uploads/demo_person.jpg\"\n",
    "        cv2.imwrite(sample_face_path, sample_face_data)\n",
    "        \n",
    "        print(\"üß™ Running demo with sample data...\")\n",
    "        test_uploaded_images()\n",
    "\n",
    "# Create demo button\n",
    "demo_button = widgets.Button(\n",
    "    description='üé¨ Run Demo',\n",
    "    style={'button_color': 'purple'},\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "def on_demo_click(b):\n",
    "    run_demo()\n",
    "\n",
    "demo_button.on_click(on_demo_click)\n",
    "\n",
    "# Display everything\n",
    "print_colab_quick_start_guide()\n",
    "display(demo_button)\n",
    "\n",
    "# Final status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ GOOGLE COLAB ANPR + FRS SYSTEM READY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üåê Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "print(f\"üñ•Ô∏è GPU Available: {IN_COLAB}\")\n",
    "print(f\"üë• Known Faces: {len(frs.known_face_names)}\")\n",
    "print(f\"üìÅ Upload Directory: uploads/\")\n",
    "print(f\"üíæ Results Directory: integrated_results/\")\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Ready to process Indian number plates and recognize faces!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6dfbc",
   "metadata": {},
   "source": [
    "## üì∑ 12. Webcam Integration (Colab Compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df088a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_webcam_capture():\n",
    "    \"\"\"Create webcam capture interface for Colab\"\"\"\n",
    "    if IN_COLAB:\n",
    "        print(\"üì∑ Webcam Integration for Google Colab\")\n",
    "        print(\"Note: Direct webcam access in Colab has limitations\")\n",
    "        print(\"Recommended: Use mobile device to capture and upload images\")\n",
    "        \n",
    "        # JavaScript webcam interface\n",
    "        from IPython.display import Javascript, HTML\n",
    "        \n",
    "        webcam_html = \"\"\"\n",
    "        <div style=\"text-align: center; padding: 20px; border: 2px dashed #4CAF50; border-radius: 10px;\">\n",
    "            <h3>üì± Mobile Camera Integration</h3>\n",
    "            <p>Use your mobile device to capture images directly:</p>\n",
    "            <input type=\"file\" accept=\"image/*\" capture=\"camera\" id=\"camera-input\" \n",
    "                   style=\"margin: 10px; padding: 10px; font-size: 16px;\">\n",
    "            <br>\n",
    "            <button onclick=\"processCamera()\" \n",
    "                    style=\"background: #4CAF50; color: white; padding: 10px 20px; \n",
    "                           border: none; border-radius: 5px; cursor: pointer; margin: 10px;\">\n",
    "                üì∏ Capture & Process\n",
    "            </button>\n",
    "            <div id=\"camera-result\" style=\"margin-top: 20px;\"></div>\n",
    "        </div>\n",
    "        \n",
    "        <script>\n",
    "        function processCamera() {\n",
    "            const input = document.getElementById('camera-input');\n",
    "            const result = document.getElementById('camera-result');\n",
    "            \n",
    "            if (input.files && input.files[0]) {\n",
    "                const file = input.files[0];\n",
    "                const reader = new FileReader();\n",
    "                \n",
    "                reader.onload = function(e) {\n",
    "                    result.innerHTML = '<img src=\"' + e.target.result + \n",
    "                                     '\" style=\"max-width: 300px; border-radius: 5px;\">' +\n",
    "                                     '<p>‚úÖ Image captured! Upload via file widget above.</p>';\n",
    "                };\n",
    "                \n",
    "                reader.readAsDataURL(file);\n",
    "            } else {\n",
    "                result.innerHTML = '<p style=\"color: red;\">‚ùå No image selected</p>';\n",
    "            }\n",
    "        }\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(webcam_html))\n",
    "        \n",
    "    else:\n",
    "        print(\"üíª Local Environment - OpenCV Webcam Available\")\n",
    "        print(\"Use cv2.VideoCapture(0) for live webcam processing\")\n",
    "\n",
    "def process_webcam_local():\n",
    "    \"\"\"Process webcam feed in local environment\"\"\"\n",
    "    if not IN_COLAB:\n",
    "        print(\"üìπ Starting local webcam processing...\")\n",
    "        print(\"Press 'q' to quit, 's' to save detection\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Could not open webcam\")\n",
    "            return\n",
    "        \n",
    "        detection_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process frame\n",
    "            results = integrated_system.process_frame(frame)\n",
    "            \n",
    "            # Draw detections\n",
    "            output_frame = integrated_system.draw_detections(frame, results)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('ANPR + FRS Live', output_frame)\n",
    "            \n",
    "            # Save significant detections\n",
    "            if results['plates'] or (results['faces'] and \n",
    "                                   any(face['name'] != 'Unknown' for face in results['faces'])):\n",
    "                detection_count += 1\n",
    "                print(f\"üéØ Detection {detection_count} found!\")\n",
    "            \n",
    "            # Controls\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s') and (results['plates'] or results['faces']):\n",
    "                integrated_system.log_detections(results)\n",
    "                print(\"üíæ Detection saved!\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"‚úÖ Webcam session ended. {detection_count} detections found.\")\n",
    "    else:\n",
    "        print(\"üì± Use mobile camera integration above for Colab\")\n",
    "\n",
    "# Create webcam interface\n",
    "webcam_button = widgets.Button(\n",
    "    description='üì∑ Setup Webcam',\n",
    "    style={'button_color': 'lightcoral'},\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "local_webcam_button = widgets.Button(\n",
    "    description='üìπ Local Webcam',\n",
    "    style={'button_color': 'lightsteelblue'},\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "def on_webcam_click(b):\n",
    "    create_webcam_capture()\n",
    "\n",
    "def on_local_webcam_click(b):\n",
    "    process_webcam_local()\n",
    "\n",
    "webcam_button.on_click(on_webcam_click)\n",
    "local_webcam_button.on_click(on_local_webcam_click)\n",
    "\n",
    "webcam_box = widgets.HBox([webcam_button, local_webcam_button])\n",
    "display(webcam_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53167fd",
   "metadata": {},
   "source": [
    "## ‚ö° 13. Batch Processing & Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fddad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_directory(directory_path=\"uploads\", output_report=True):\n",
    "    \"\"\"Batch process all images and videos in a directory\"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"‚ùå Directory not found: {directory_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get all supported files\n",
    "    supported_extensions = ('.jpg', '.jpeg', '.png', '.mp4', '.avi', '.mov')\n",
    "    files = [f for f in os.listdir(directory_path) \n",
    "             if f.lower().endswith(supported_extensions)]\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"üìÅ No supported files found in {directory_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üöÄ Batch processing {len(files)} files...\")\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {\n",
    "        'total_files': len(files),\n",
    "        'processed_files': 0,\n",
    "        'total_plates': 0,\n",
    "        'total_faces': 0,\n",
    "        'processing_time': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(files, desc=\"Processing files\")\n",
    "    \n",
    "    for filename in pbar:\n",
    "        try:\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            pbar.set_description(f\"Processing {filename}\")\n",
    "            \n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                # Process image\n",
    "                image = cv2.imread(file_path)\n",
    "                if image is not None:\n",
    "                    results = integrated_system.process_frame(image)\n",
    "                    \n",
    "                    if results['plates'] or results['faces']:\n",
    "                        integrated_system.log_detections(results)\n",
    "                    \n",
    "                    stats['total_plates'] += len(results['plates'])\n",
    "                    stats['total_faces'] += len(results['faces'])\n",
    "                    stats['processed_files'] += 1\n",
    "            \n",
    "            elif filename.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "                # Process video\n",
    "                process_video_colab(file_path, sample_frames=10)\n",
    "                stats['processed_files'] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "            stats['errors'] += 1\n",
    "    \n",
    "    stats['processing_time'] = time.time() - start_time\n",
    "    pbar.close()\n",
    "    \n",
    "    # Generate report\n",
    "    if output_report:\n",
    "        print(\"\\nüìä BATCH PROCESSING REPORT\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"üìÅ Total files: {stats['total_files']}\")\n",
    "        print(f\"‚úÖ Processed: {stats['processed_files']}\")\n",
    "        print(f\"‚ùå Errors: {stats['errors']}\")\n",
    "        print(f\"üöó Total plates detected: {stats['total_plates']}\")\n",
    "        print(f\"üë§ Total faces detected: {stats['total_faces']}\")\n",
    "        print(f\"‚è±Ô∏è Processing time: {stats['processing_time']:.2f} seconds\")\n",
    "        print(f\"‚ö° Average time per file: {stats['processing_time']/max(1,stats['processed_files']):.2f} seconds\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def monitor_system_performance():\n",
    "    \"\"\"Monitor system performance and resource usage\"\"\"\n",
    "    import psutil\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    print(\"üñ•Ô∏è SYSTEM PERFORMANCE MONITOR\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # CPU and Memory info\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory = psutil.virtual_memory()\n",
    "    \n",
    "    print(f\"üî• CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"üíæ Memory Usage: {memory.percent}%\")\n",
    "    print(f\"üìä Available Memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        # Check GPU status in Colab\n",
    "        try:\n",
    "            gpu_info = !nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free --format=csv,noheader,nounits\n",
    "            if gpu_info:\n",
    "                print(\"üéÆ GPU Information:\")\n",
    "                for line in gpu_info:\n",
    "                    parts = line.split(', ')\n",
    "                    if len(parts) >= 4:\n",
    "                        name, total, used, free = parts[:4]\n",
    "                        print(f\"  GPU: {name}\")\n",
    "                        print(f\"  Memory: {used}MB / {total}MB used\")\n",
    "                        print(f\"  Free: {free}MB\")\n",
    "        except:\n",
    "            print(\"üéÆ GPU: Not available or not accessible\")\n",
    "    \n",
    "    # Disk usage\n",
    "    disk = psutil.disk_usage('.')\n",
    "    print(f\"üíΩ Disk Usage: {disk.percent}%\")\n",
    "    print(f\"üìÅ Free Space: {disk.free / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # Create performance visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # CPU gauge\n",
    "    axes[0].pie([cpu_percent, 100-cpu_percent], labels=['Used', 'Free'], \n",
    "                colors=['red', 'lightgreen'], startangle=90)\n",
    "    axes[0].set_title(f'CPU Usage ({cpu_percent}%)')\n",
    "    \n",
    "    # Memory gauge\n",
    "    axes[1].pie([memory.percent, 100-memory.percent], labels=['Used', 'Free'],\n",
    "                colors=['orange', 'lightblue'], startangle=90)\n",
    "    axes[1].set_title(f'Memory Usage ({memory.percent}%)')\n",
    "    \n",
    "    # Disk gauge\n",
    "    axes[2].pie([disk.percent, 100-disk.percent], labels=['Used', 'Free'],\n",
    "                colors=['purple', 'yellow'], startangle=90)\n",
    "    axes[2].set_title(f'Disk Usage ({disk.percent}%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def system_health_check():\n",
    "    \"\"\"Perform comprehensive system health check\"\"\"\n",
    "    print(\"üè• SYSTEM HEALTH CHECK\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    health_status = {\n",
    "        'anpr_system': False,\n",
    "        'frs_system': False,\n",
    "        'integrated_system': False,\n",
    "        'file_access': False,\n",
    "        'results_directory': False\n",
    "    }\n",
    "    \n",
    "    # Test ANPR system\n",
    "    try:\n",
    "        test_image = np.zeros((100, 200, 3), dtype=np.uint8)\n",
    "        anpr.process_image(test_image)\n",
    "        health_status['anpr_system'] = True\n",
    "        print(\"‚úÖ ANPR System: Operational\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ANPR System: Error - {e}\")\n",
    "    \n",
    "    # Test FRS system\n",
    "    try:\n",
    "        test_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        frs.detect_faces(test_image)\n",
    "        health_status['frs_system'] = True\n",
    "        print(\"‚úÖ FRS System: Operational\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FRS System: Error - {e}\")\n",
    "    \n",
    "    # Test integrated system\n",
    "    try:\n",
    "        test_image = np.zeros((200, 300, 3), dtype=np.uint8)\n",
    "        integrated_system.process_frame(test_image)\n",
    "        health_status['integrated_system'] = True\n",
    "        print(\"‚úÖ Integrated System: Operational\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Integrated System: Error - {e}\")\n",
    "    \n",
    "    # Test file access\n",
    "    try:\n",
    "        test_file = \"health_check_test.txt\"\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        health_status['file_access'] = True\n",
    "        print(\"‚úÖ File Access: Operational\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå File Access: Error - {e}\")\n",
    "    \n",
    "    # Check results directories\n",
    "    required_dirs = ['uploads', 'anpr_results', 'face_results', 'integrated_results', 'known_faces']\n",
    "    all_dirs_exist = all(os.path.exists(d) for d in required_dirs)\n",
    "    \n",
    "    if all_dirs_exist:\n",
    "        health_status['results_directory'] = True\n",
    "        print(\"‚úÖ Results Directories: All present\")\n",
    "    else:\n",
    "        print(\"‚ùå Results Directories: Some missing\")\n",
    "        for d in required_dirs:\n",
    "            if not os.path.exists(d):\n",
    "                print(f\"  Missing: {d}\")\n",
    "    \n",
    "    # Overall health score\n",
    "    health_score = sum(health_status.values()) / len(health_status) * 100\n",
    "    \n",
    "    print(f\"\\nüè• Overall Health Score: {health_score:.1f}%\")\n",
    "    \n",
    "    if health_score == 100:\n",
    "        print(\"üéâ System Status: EXCELLENT\")\n",
    "    elif health_score >= 80:\n",
    "        print(\"‚úÖ System Status: GOOD\")\n",
    "    elif health_score >= 60:\n",
    "        print(\"‚ö†Ô∏è System Status: FAIR - Some issues detected\")\n",
    "    else:\n",
    "        print(\"‚ùå System Status: POOR - Multiple issues detected\")\n",
    "    \n",
    "    return health_status\n",
    "\n",
    "# Create monitoring buttons\n",
    "batch_button = widgets.Button(\n",
    "    description='‚ö° Batch Process',\n",
    "    style={'button_color': 'lightcyan'},\n",
    "    layout=widgets.Layout(width='140px')\n",
    ")\n",
    "\n",
    "performance_button = widgets.Button(\n",
    "    description='üñ•Ô∏è Performance',\n",
    "    style={'button_color': 'lightyellow'},\n",
    "    layout=widgets.Layout(width='140px')\n",
    ")\n",
    "\n",
    "health_button = widgets.Button(\n",
    "    description='üè• Health Check',\n",
    "    style={'button_color': 'lightpink'},\n",
    "    layout=widgets.Layout(width='140px')\n",
    ")\n",
    "\n",
    "def on_batch_click(b):\n",
    "    batch_process_directory()\n",
    "\n",
    "def on_performance_click(b):\n",
    "    monitor_system_performance()\n",
    "\n",
    "def on_health_click(b):\n",
    "    system_health_check()\n",
    "\n",
    "batch_button.on_click(on_batch_click)\n",
    "performance_button.on_click(on_performance_click)\n",
    "health_button.on_click(on_health_click)\n",
    "\n",
    "monitoring_box = widgets.HBox([batch_button, performance_button, health_button])\n",
    "display(monitoring_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fe40a",
   "metadata": {},
   "source": [
    "## üéØ 14. System Status & Final Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_final_system_status():\n",
    "    \"\"\"Display comprehensive final system status\"\"\"\n",
    "    \n",
    "    # Create a beautiful status display\n",
    "    status_html = f\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%); \n",
    "                padding: 25px; border-radius: 15px; color: white; \n",
    "                font-family: 'Segoe UI', Arial, sans-serif; margin: 20px 0;\">\n",
    "        \n",
    "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "            <h1 style=\"margin: 0; font-size: 2.5em;\">üéâ SYSTEM READY!</h1>\n",
    "            <p style=\"font-size: 1.2em; margin: 10px 0;\">Indian ANPR + FRS System - Google Colab Optimized</p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); \n",
    "                    gap: 15px; margin: 20px 0;\">\n",
    "            \n",
    "            <div style=\"background: rgba(255,255,255,0.15); padding: 15px; \n",
    "                        border-radius: 10px; text-align: center;\">\n",
    "                <h3 style=\"margin: 0 0 10px 0;\">üåê Environment</h3>\n",
    "                <p style=\"margin: 5px 0; font-size: 1.1em;\">\n",
    "                    {'Google Colab' if IN_COLAB else 'Local Jupyter'}\n",
    "                </p>\n",
    "                <p style=\"margin: 5px 0;\">GPU: {'Available' if IN_COLAB else 'Check Local'}</p>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: rgba(255,255,255,0.15); padding: 15px; \n",
    "                        border-radius: 10px; text-align: center;\">\n",
    "                <h3 style=\"margin: 0 0 10px 0;\">üöó ANPR System</h3>\n",
    "                <p style=\"margin: 5px 0; font-size: 1.1em;\">EasyOCR Engine</p>\n",
    "                <p style=\"margin: 5px 0;\">Indian Format Optimized</p>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: rgba(255,255,255,0.15); padding: 15px; \n",
    "                        border-radius: 10px; text-align: center;\">\n",
    "                <h3 style=\"margin: 0 0 10px 0;\">üë§ FRS System</h3>\n",
    "                <p style=\"margin: 5px 0; font-size: 1.1em;\">face_recognition</p>\n",
    "                <p style=\"margin: 5px 0;\">{len(frs.known_face_names)} Known Faces</p>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: rgba(255,255,255,0.15); padding: 15px; \n",
    "                        border-radius: 10px; text-align: center;\">\n",
    "                <h3 style=\"margin: 0 0 10px 0;\">üíæ Storage</h3>\n",
    "                <p style=\"margin: 5px 0; font-size: 1.1em;\">Results Saved</p>\n",
    "                <p style=\"margin: 5px 0;\">Auto-logging Enabled</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(255,255,255,0.2); padding: 20px; \n",
    "                    border-radius: 10px; margin: 20px 0;\">\n",
    "            <h3 style=\"text-align: center; margin: 0 0 15px 0;\">üöÄ Ready to Use Features</h3>\n",
    "            <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); \n",
    "                        gap: 10px; text-align: center;\">\n",
    "                <div>üìÅ File Upload</div>\n",
    "                <div>üë• Face Database</div>\n",
    "                <div>üß™ Image Testing</div>\n",
    "                <div>üé• Video Processing</div>\n",
    "                <div>üìä Results Analysis</div>\n",
    "                <div>üì• Data Export</div>\n",
    "                <div>üì∑ Webcam Integration</div>\n",
    "                <div>‚ö° Batch Processing</div>\n",
    "                <div>üñ•Ô∏è Performance Monitor</div>\n",
    "                <div>üè• Health Checks</div>\n",
    "                <div>‚öôÔ∏è Configuration</div>\n",
    "                <div>üé¨ Demo Mode</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: center; margin-top: 20px;\">\n",
    "            <p style=\"font-size: 1.1em; margin: 10px 0;\">‚ú® All systems initialized and ready for operation!</p>\n",
    "            <p style=\"font-size: 0.9em; opacity: 0.8;\">Use the buttons above to start processing</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(status_html))\n",
    "\n",
    "def create_all_action_buttons():\n",
    "    \"\"\"Create a comprehensive control panel with all available actions\"\"\"\n",
    "    \n",
    "    # Define all buttons with their properties\n",
    "    buttons_config = [\n",
    "        ('üìÅ Upload Files', 'lightblue', lambda: upload_files()),\n",
    "        ('üë• Add Faces', 'lightgreen', lambda: add_face_from_upload()),\n",
    "        ('üß™ Test Images', 'yellow', lambda: test_uploaded_images()),\n",
    "        ('üìä Analyze Results', 'orange', lambda: view_detection_results()),\n",
    "        ('üì• Download Results', 'lightcoral', lambda: download_results()),\n",
    "        ('üé¨ Run Demo', 'purple', lambda: run_demo()),\n",
    "        ('üì∑ Setup Webcam', 'lightcyan', lambda: create_webcam_capture()),\n",
    "        ('‚ö° Batch Process', 'lightyellow', lambda: batch_process_directory()),\n",
    "        ('üñ•Ô∏è Performance', 'lightpink', lambda: monitor_system_performance()),\n",
    "        ('üè• Health Check', 'lightsteelblue', lambda: system_health_check()),\n",
    "    ]\n",
    "    \n",
    "    # Create buttons\n",
    "    buttons = []\n",
    "    for desc, color, func in buttons_config:\n",
    "        button = widgets.Button(\n",
    "            description=desc,\n",
    "            style={'button_color': color},\n",
    "            layout=widgets.Layout(width='180px', height='35px', margin='2px')\n",
    "        )\n",
    "        button.on_click(lambda x, f=func: f())\n",
    "        buttons.append(button)\n",
    "    \n",
    "    # Arrange in grid\n",
    "    rows = []\n",
    "    for i in range(0, len(buttons), 3):\n",
    "        row = widgets.HBox(buttons[i:i+3], layout=widgets.Layout(justify_content='center'))\n",
    "        rows.append(row)\n",
    "    \n",
    "    control_panel = widgets.VBox([\n",
    "        widgets.HTML(\"<h3 style='text-align: center; margin: 20px 0;'>üéõÔ∏è CONTROL PANEL</h3>\"),\n",
    "        *rows\n",
    "    ])\n",
    "    \n",
    "    return control_panel\n",
    "\n",
    "# Display final status and control panel\n",
    "display_final_system_status()\n",
    "control_panel = create_all_action_buttons()\n",
    "display(control_panel)\n",
    "\n",
    "# Final system check\n",
    "print(\"\\nüîç Performing final system verification...\")\n",
    "health_status = system_health_check()\n",
    "\n",
    "if all(health_status.values()):\n",
    "    print(\"\\nüéâ SUCCESS: All systems operational!\")\n",
    "    print(\"üöÄ Ready to process Indian number plates and recognize faces!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Some systems may need attention\")\n",
    "    print(\"üîß Check the health status above for details\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ INDIAN ANPR + FRS SYSTEM - GOOGLE COLAB EDITION\")\n",
    "print(\"üåü Optimized for cloud processing with interactive widgets\")\n",
    "print(\"üìö TensorFlow-free implementation using face_recognition library\")\n",
    "print(\"üöó Specialized for Indian vehicle number plate recognition\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb614f1",
   "metadata": {},
   "source": [
    "## ‚úÖ Notebook Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2177e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK COMPLETION STATUS\n",
    "print(\"üè° GOOGLE COLAB ANPR + FRS SYSTEM - COMPLETION STATUS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ COMPLETED FEATURES:\")\n",
    "print(\"   üîß Environment Setup & Package Installation\")\n",
    "print(\"   üìö Library Imports (TensorFlow-free)\")\n",
    "print(\"   üåê Google Drive Integration\")\n",
    "print(\"   üöó Indian Number Plate Recognition (EasyOCR)\")\n",
    "print(\"   üë§ Facial Recognition System (face_recognition)\")\n",
    "print(\"   üîó Integrated ANPR + FRS System\")\n",
    "print(\"   üìÅ File Upload & Management (Colab Optimized)\")\n",
    "print(\"   üë• Interactive Face Database Management\")\n",
    "print(\"   üß™ Image & Video Testing Functions\")\n",
    "print(\"   üìä Results Analysis & Visualization\")\n",
    "print(\"   ‚öôÔ∏è System Configuration Interface\")\n",
    "print(\"   üöÄ Quick Start Guide & Demo\")\n",
    "print(\"   üì∑ Webcam Integration (Colab Compatible)\")\n",
    "print(\"   ‚ö° Batch Processing & Performance Monitoring\")\n",
    "print(\"   üè• System Health Checks\")\n",
    "print(\"   üì• Results Download & Export\")\n",
    "print(\"   üûõÔ∏è Interactive Control Panel\")\n",
    "print(\"\\nüéÜ ENHANCEMENT HIGHLIGHTS:\")\n",
    "print(\"   ‚ú® Colab-specific optimizations\")\n",
    "print(\"   üì± Mobile camera integration\")\n",
    "print(\"   üé® Interactive widgets & beautiful UI\")\n",
    "print(\"   üìä Enhanced visualization with matplotlib\")\n",
    "print(\"   üöÄ Improved Indian number plate detection\")\n",
    "print(\"   üìÖ Comprehensive logging & CSV export\")\n",
    "print(\"   üñ•Ô∏è Real-time performance monitoring\")\n",
    "print(\"   üîÑ Progress bars for long operations\")\n",
    "print(\"\\nüìé USAGE INSTRUCTIONS:\")\n",
    "print(\"1. üìÅ Upload images/videos using the file upload widget\")\n",
    "print(\"2. üë• Add known faces to the database\")\n",
    "print(\"3. üß™ Test the system with your uploaded files\")\n",
    "print(\"4. üìä Analyze results and download data\")\n",
    "print(\"5. ‚öôÔ∏è Adjust configuration as needed\")\n",
    "print(\"\\nüéâ The notebook is now fully operational and ready for use!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
