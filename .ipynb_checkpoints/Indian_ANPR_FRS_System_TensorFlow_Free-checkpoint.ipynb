{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c470a77c",
   "metadata": {},
   "source": [
    "# Indian Vehicle Number Plate Recognition & Facial Recognition System\n",
    "## TensorFlow-Free Version\n",
    "\n",
    "A focused implementation combining:\n",
    "- **Automatic Number Plate Recognition (ANPR)** optimized for Indian number plates\n",
    "- **Facial Recognition System (FRS)** for person identification\n",
    "\n",
    "## Features:\n",
    "- Real-time processing from webcam or video files\n",
    "- Indian number plate format detection\n",
    "- EasyOCR for accurate text extraction\n",
    "- face_recognition library for facial recognition (no TensorFlow dependency)\n",
    "- Integrated processing pipeline\n",
    "- Jupyter-ready visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633b60f",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (TensorFlow-free version)\n",
    "!pip install opencv-python easyocr face-recognition scikit-learn numpy matplotlib pillow\n",
    "!pip install dlib  # Required for face_recognition\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb819fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import face_recognition  # TensorFlow-free alternative\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import uuid\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Using face_recognition library instead of TensorFlow for facial recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba695c1",
   "metadata": {},
   "source": [
    "## 2. Indian Number Plate Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianANPR:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Indian ANPR system with EasyOCR\"\"\"\n",
    "        self.reader = easyocr.Reader(['en'], gpu=True)  # Enable GPU if available\n",
    "        \n",
    "        # Indian number plate patterns\n",
    "        self.indian_patterns = [\n",
    "            r'[A-Z]{2}\\s?[0-9]{1,2}\\s?[A-Z]{1,2}\\s?[0-9]{1,4}',  # Standard format: XX 00 XX 0000\n",
    "            r'[A-Z]{2}[0-9]{1,2}[A-Z]{1,2}[0-9]{1,4}',           # Without spaces\n",
    "            r'[0-9]{2}\\s?BH\\s?[0-9]{4}\\s?[A-Z]{2}',              # Bharat series\n",
    "            r'[0-9]{2}BH[0-9]{4}[A-Z]{2}',                        # Bharat series without spaces\n",
    "        ]\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('anpr_results', exist_ok=True)\n",
    "        \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply bilateral filter to reduce noise while keeping edges sharp\n",
    "        filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "        \n",
    "        # Find edges\n",
    "        edged = cv2.Canny(filtered, 30, 200)\n",
    "        \n",
    "        return gray, filtered, edged\n",
    "    \n",
    "    def find_license_plate_contours(self, edged_image):\n",
    "        \"\"\"Find potential license plate contours\"\"\"\n",
    "        contours, _ = cv2.findContours(edged_image.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "        \n",
    "        license_plate_contours = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Approximate contour\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.018 * perimeter, True)\n",
    "            \n",
    "            # Check if contour has 4 corners (rectangle-like)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h\n",
    "                \n",
    "                # Indian license plates typically have aspect ratio between 2:1 and 4:1\n",
    "                if 2.0 <= aspect_ratio <= 4.5 and w > 100 and h > 30:\n",
    "                    license_plate_contours.append((x, y, w, h, contour))\n",
    "        \n",
    "        return license_plate_contours\n",
    "    \n",
    "    def extract_text_from_roi(self, image, roi):\n",
    "        \"\"\"Extract text from Region of Interest using EasyOCR\"\"\"\n",
    "        x, y, w, h = roi[:4]\n",
    "        plate_region = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize for better OCR\n",
    "        plate_region = cv2.resize(plate_region, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Apply additional preprocessing\n",
    "        plate_gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n",
    "        plate_thresh = cv2.threshold(plate_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        \n",
    "        # Use EasyOCR to extract text\n",
    "        try:\n",
    "            results = self.reader.readtext(plate_thresh)\n",
    "            if results:\n",
    "                # Combine all detected text\n",
    "                text = ' '.join([result[1] for result in results if result[2] > 0.5])\n",
    "                return self.validate_indian_plate(text), plate_region\n",
    "        except Exception as e:\n",
    "            print(f\"OCR Error: {e}\")\n",
    "        \n",
    "        return None, plate_region\n",
    "    \n",
    "    def validate_indian_plate(self, text):\n",
    "        \"\"\"Validate if text matches Indian number plate patterns\"\"\"\n",
    "        if not text:\n",
    "            return None\n",
    "            \n",
    "        # Clean the text\n",
    "        cleaned_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "        \n",
    "        # Check against Indian patterns\n",
    "        for pattern in self.indian_patterns:\n",
    "            if re.match(pattern, text.upper()):\n",
    "                return text.upper()\n",
    "            if re.match(pattern, cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        # If no exact match, check if it looks like a valid plate\n",
    "        if len(cleaned_text) >= 6 and len(cleaned_text) <= 10:\n",
    "            # Basic validation: should have letters and numbers\n",
    "            if re.search(r'[A-Z]', cleaned_text) and re.search(r'[0-9]', cleaned_text):\n",
    "                return cleaned_text\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def process_image(self, image):\n",
    "        \"\"\"Process image and detect Indian number plates\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Preprocess image\n",
    "        gray, filtered, edged = self.preprocess_image(image)\n",
    "        \n",
    "        # Find potential license plate contours\n",
    "        plate_contours = self.find_license_plate_contours(edged)\n",
    "        \n",
    "        # Process each potential plate\n",
    "        for roi in plate_contours:\n",
    "            plate_text, plate_image = self.extract_text_from_roi(image, roi)\n",
    "            \n",
    "            if plate_text:\n",
    "                results.append({\n",
    "                    'text': plate_text,\n",
    "                    'bbox': roi[:4],\n",
    "                    'confidence': 0.8,  # Placeholder confidence\n",
    "                    'plate_image': plate_image\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_detection(self, plate_image, plate_text, confidence, timestamp):\n",
    "        \"\"\"Save plate detection with timestamp\"\"\"\n",
    "        filename = f\"anpr_results/plate_{timestamp}_{plate_text.replace(' ', '_')}.jpg\"\n",
    "        cv2.imwrite(filename, plate_image)\n",
    "        return filename\n",
    "\n",
    "# Initialize ANPR system\n",
    "anpr = IndianANPR()\n",
    "print(\"Indian ANPR system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e5f82",
   "metadata": {},
   "source": [
    "## 3. Facial Recognition System (TensorFlow-Free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64473a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize facial recognition system using face_recognition library\"\"\"\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs('face_results', exist_ok=True)\n",
    "        os.makedirs('known_faces', exist_ok=True)\n",
    "        \n",
    "        print(\"Facial Recognition System initialized with face_recognition library\")\n",
    "        \n",
    "    def detect_faces(self, image):\n",
    "        \"\"\"Detect faces in image using face_recognition library\"\"\"\n",
    "        # Convert BGR to RGB (face_recognition uses RGB)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face locations\n",
    "        face_locations = face_recognition.face_locations(rgb_image)\n",
    "        \n",
    "        # Convert to (x, y, w, h) format for consistency with OpenCV\n",
    "        faces = []\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            faces.append((left, top, right - left, bottom - top))\n",
    "        \n",
    "        return faces\n",
    "    \n",
    "    def extract_face_encoding(self, image, face_location=None):\n",
    "        \"\"\"Extract face encoding using face_recognition library\"\"\"\n",
    "        # Convert BGR to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if face_location is not None:\n",
    "            # Convert (x, y, w, h) to (top, right, bottom, left)\n",
    "            x, y, w, h = face_location\n",
    "            face_location = (y, x + w, y + h, x)\n",
    "            face_locations = [face_location]\n",
    "        else:\n",
    "            face_locations = face_recognition.face_locations(rgb_image)\n",
    "        \n",
    "        if not face_locations:\n",
    "            return None\n",
    "        \n",
    "        # Get face encodings\n",
    "        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "        \n",
    "        if face_encodings:\n",
    "            return face_encodings[0]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def add_known_face(self, image, name):\n",
    "        \"\"\"Add a known face to the database\"\"\"\n",
    "        faces = self.detect_faces(image)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            print(f\"No face detected for {name}\")\n",
    "            return False\n",
    "        \n",
    "        if len(faces) > 1:\n",
    "            print(f\"Multiple faces detected for {name}. Using the largest one.\")\n",
    "        \n",
    "        # Use the largest face\n",
    "        face = max(faces, key=lambda x: x[2] * x[3])\n",
    "        x, y, w, h = face\n",
    "        face_image = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Extract face encoding\n",
    "        encoding = self.extract_face_encoding(image, face)\n",
    "        \n",
    "        if encoding is None:\n",
    "            print(f\"Could not encode face for {name}\")\n",
    "            return False\n",
    "        \n",
    "        # Store encoding and name\n",
    "        self.known_face_encodings.append(encoding)\n",
    "        self.known_face_names.append(name)\n",
    "        \n",
    "        # Save face image\n",
    "        face_filename = f\"known_faces/{name}_{len(self.known_face_encodings)}.jpg\"\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "        \n",
    "        print(f\"Added {name} to known faces database\")\n",
    "        return True\n",
    "    \n",
    "    def recognize_faces(self, image, tolerance=0.6):\n",
    "        \"\"\"Recognize faces in image\"\"\"\n",
    "        if len(self.known_face_encodings) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face locations and encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_image)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, face_encoding in enumerate(face_encodings):\n",
    "            # Compare with known faces\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding, tolerance)\n",
    "            \n",
    "            name = \"Unknown\"\n",
    "            confidence = 0.0\n",
    "            \n",
    "            if True in matches:\n",
    "                # Find the best match\n",
    "                best_match_index = np.argmin(distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = self.known_face_names[best_match_index]\n",
    "                    # Convert distance to confidence (0-1 scale)\n",
    "                    confidence = max(0, 1 - distances[best_match_index])\n",
    "            \n",
    "            # Convert face location to (x, y, w, h) format\n",
    "            top, right, bottom, left = face_locations[i]\n",
    "            x, y, w, h = left, top, right - left, bottom - top\n",
    "            \n",
    "            # Extract face image\n",
    "            face_image = image[y:y+h, x:x+w]\n",
    "            \n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'confidence': confidence,\n",
    "                'bbox': (x, y, w, h),\n",
    "                'face_image': face_image\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_detection(self, face_image, name, confidence, timestamp):\n",
    "        \"\"\"Save face detection with timestamp\"\"\"\n",
    "        filename = f\"face_results/face_{timestamp}_{name}_{confidence:.2f}.jpg\"\n",
    "        cv2.imwrite(filename, face_image)\n",
    "        return filename\n",
    "    \n",
    "    def save_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Save known faces database to file\"\"\"\n",
    "        database = {\n",
    "            'encodings': self.known_face_encodings,\n",
    "            'names': self.known_face_names\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(database, f)\n",
    "        \n",
    "        print(f\"Face database saved to {filename}\")\n",
    "    \n",
    "    def load_database(self, filename=\"face_database.pkl\"):\n",
    "        \"\"\"Load known faces database from file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                database = pickle.load(f)\n",
    "            \n",
    "            self.known_face_encodings = database['encodings']\n",
    "            self.known_face_names = database['names']\n",
    "            \n",
    "            print(f\"Face database loaded from {filename}\")\n",
    "            print(f\"Loaded {len(self.known_face_names)} known faces\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Database file {filename} not found\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading database: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize FRS system\n",
    "frs = FacialRecognitionSystem()\n",
    "print(\"Facial Recognition System initialized with face_recognition library!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750465e7",
   "metadata": {},
   "source": [
    "## 4. Integrated ANPR + FRS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedANPR_FRS:\n",
    "    def __init__(self, anpr_system, frs_system):\n",
    "        \"\"\"Initialize integrated ANPR + FRS system\"\"\"\n",
    "        self.anpr = anpr_system\n",
    "        self.frs = frs_system\n",
    "        \n",
    "        # Create integrated results directory\n",
    "        os.makedirs('integrated_results', exist_ok=True)\n",
    "        \n",
    "        # Initialize CSV file with headers\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        if not os.path.exists(csv_filename):\n",
    "            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    'timestamp', 'plate_text', 'plate_confidence',\n",
    "                    'face_name', 'face_confidence', 'plate_image_path', 'face_image_path'\n",
    "                ])\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for both ANPR and FRS\"\"\"\n",
    "        results = {\n",
    "            'plates': [],\n",
    "            'faces': []\n",
    "        }\n",
    "        \n",
    "        # Process ANPR\n",
    "        try:\n",
    "            plate_results = self.anpr.process_image(frame)\n",
    "            results['plates'] = plate_results\n",
    "        except Exception as e:\n",
    "            print(f\"ANPR Error: {e}\")\n",
    "        \n",
    "        # Process FRS\n",
    "        try:\n",
    "            face_results = self.frs.recognize_faces(frame)\n",
    "            results['faces'] = face_results\n",
    "        except Exception as e:\n",
    "            print(f\"FRS Error: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def log_detections(self, results):\n",
    "        \"\"\"Log detection results to CSV and save images\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        \n",
    "        # Default values\n",
    "        plate_text = \"\"\n",
    "        plate_confidence = 0.0\n",
    "        face_name = \"\"\n",
    "        face_confidence = 0.0\n",
    "        plate_image = \"\"\n",
    "        face_image = \"\"\n",
    "        \n",
    "        # Process plate detections\n",
    "        if results['plates']:\n",
    "            best_plate = max(results['plates'], key=lambda x: x['confidence'])\n",
    "            plate_text = best_plate['text']\n",
    "            plate_confidence = best_plate['confidence']\n",
    "            plate_image = self.anpr.save_detection(\n",
    "                best_plate['plate_image'], plate_text, plate_confidence, timestamp\n",
    "            )\n",
    "        \n",
    "        # Process face detections\n",
    "        if results['faces']:\n",
    "            best_face = max(results['faces'], key=lambda x: x['confidence'])\n",
    "            face_name = best_face['name']\n",
    "            face_confidence = best_face['confidence']\n",
    "            face_image = self.frs.save_detection(\n",
    "                best_face['face_image'], face_name, face_confidence, timestamp\n",
    "            )\n",
    "        \n",
    "        # Save to combined CSV\n",
    "        csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                timestamp, plate_text, plate_confidence,\n",
    "                face_name, face_confidence, plate_image, face_image\n",
    "            ])\n",
    "    \n",
    "    def draw_detections(self, frame, results):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Draw license plates\n",
    "        for plate in results['plates']:\n",
    "            x, y, w, h = plate['bbox']\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(output_frame, f\"Plate: {plate['text']}\", \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw faces\n",
    "        for face in results['faces']:\n",
    "            x, y, w, h = face['bbox']\n",
    "            color = (0, 255, 255) if face['name'] != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            label = f\"{face['name']} ({face['confidence']:.2f})\"\n",
    "            cv2.putText(output_frame, label, \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        return output_frame\n",
    "\n",
    "# Initialize integrated system\n",
    "integrated_system = IntegratedANPR_FRS(anpr, frs)\n",
    "print(\"Integrated ANPR + FRS system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5175e",
   "metadata": {},
   "source": [
    "## 5. Setup Known Faces Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f05fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add known faces from images\n",
    "def add_sample_faces():\n",
    "    \"\"\"Add sample faces to the database\"\"\"\n",
    "    # You can add your own face images here\n",
    "    # Example: Load images from a directory\n",
    "    \n",
    "    sample_faces_dir = \"sample_faces\"\n",
    "    if os.path.exists(sample_faces_dir):\n",
    "        for filename in os.listdir(sample_faces_dir):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                image_path = os.path.join(sample_faces_dir, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    frs.add_known_face(image, name)\n",
    "                    print(f\"Added {name} to database\")\n",
    "    else:\n",
    "        print(\"Sample faces directory not found. Create 'sample_faces' folder and add face images.\")\n",
    "        print(\"Or use the webcam capture function below to add faces.\")\n",
    "\n",
    "# Add sample faces\n",
    "add_sample_faces()\n",
    "\n",
    "# Try to load existing database\n",
    "frs.load_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture and add face from webcam\n",
    "def capture_and_add_face(name):\n",
    "    \"\"\"Capture face from webcam and add to database\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Capturing face for {name}. Press SPACE to capture, ESC to cancel.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect faces for preview\n",
    "        faces = frs.detect_faces(frame)\n",
    "        \n",
    "        # Draw rectangles around faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, f\"Capturing: {name}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"SPACE: Capture, ESC: Cancel\", (10, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Face', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):  # Space to capture\n",
    "            if frs.add_known_face(frame, name):\n",
    "                print(f\"Successfully added {name} to database!\")\n",
    "                # Save the updated database\n",
    "                frs.save_database()\n",
    "            break\n",
    "        elif key == 27:  # ESC to cancel\n",
    "            print(\"Capture cancelled\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# capture_and_add_face(\"YourName\")\n",
    "\n",
    "print(\"Webcam capture function ready. Call capture_and_add_face('Name') to add faces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d2721",
   "metadata": {},
   "source": [
    "## 6. Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample_image(image_path):\n",
    "    \"\"\"Test the system with a sample image\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    \n",
    "    # Process with integrated system\n",
    "    results = integrated_system.process_frame(image)\n",
    "    \n",
    "    # Draw detections\n",
    "    output_image = integrated_system.draw_detections(image, results)\n",
    "    \n",
    "    # Log detections\n",
    "    integrated_system.log_detections(results)\n",
    "    \n",
    "    # Display results using matplotlib\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Processed image\n",
    "    axes[1].imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('Detections')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== DETECTION RESULTS ===\")\n",
    "    print(f\"License Plates Detected: {len(results['plates'])}\")\n",
    "    for i, plate in enumerate(results['plates']):\n",
    "        print(f\"  Plate {i+1}: {plate['text']} (Confidence: {plate['confidence']:.2f})\")\n",
    "    \n",
    "    print(f\"\\nFaces Detected: {len(results['faces'])}\")\n",
    "    for i, face in enumerate(results['faces']):\n",
    "        print(f\"  Face {i+1}: {face['name']} (Confidence: {face['confidence']:.2f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment and modify path to test):\n",
    "# results = test_sample_image(\"test_image.jpg\")\n",
    "\n",
    "print(\"Test function ready. Call test_sample_image('path/to/image.jpg') to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea982b69",
   "metadata": {},
   "source": [
    "## 7. Real-time Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realtime_detection():\n",
    "    \"\"\"Run real-time detection from webcam\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"Starting real-time detection. Press 'q' to quit, 's' to save current frame.\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    process_every_n_frames = 5  # Process every 5th frame for better performance\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Process frame\n",
    "        if frame_count % process_every_n_frames == 0:\n",
    "            results = integrated_system.process_frame(frame)\n",
    "            \n",
    "            # Log significant detections\n",
    "            if results['plates'] or (results['faces'] and \n",
    "                                   any(face['name'] != 'Unknown' for face in results['faces'])):\n",
    "                integrated_system.log_detections(results)\n",
    "            \n",
    "            # Draw detections\n",
    "            frame = integrated_system.draw_detections(frame, results)\n",
    "        \n",
    "        # Add frame counter and instructions\n",
    "        cv2.putText(frame, f\"Frame: {frame_count}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press 'q' to quit, 's' to save\", (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        cv2.imshow('ANPR + FRS Real-time Detection', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            # Save current frame\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            cv2.imwrite(f\"integrated_results/realtime_capture_{timestamp}.jpg\", frame)\n",
    "            print(f\"Frame saved as realtime_capture_{timestamp}.jpg\")\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Real-time detection completed. Processed {frame_count} frames.\")\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# run_realtime_detection()\n",
    "\n",
    "print(\"Real-time detection function ready. Call run_realtime_detection() to start.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de507e2",
   "metadata": {},
   "source": [
    "## 8. Video File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_file(input_path, output_path=None):\n",
    "    \"\"\"Process video file and save results\"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Video file not found: {input_path}\")\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {input_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {input_path}\")\n",
    "    print(f\"Properties: {frame_width}x{frame_height}, {fps} FPS, {total_frames} frames\")\n",
    "    \n",
    "    # Setup output video writer if path provided\n",
    "    out = None\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    detection_count = 0\n",
    "    process_every_n_frames = 10  # Process every 10th frame for performance\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Show progress\n",
    "        if frame_count % 100 == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "        \n",
    "        # Process frame\n",
    "        if frame_count % process_every_n_frames == 0:\n",
    "            results = integrated_system.process_frame(frame)\n",
    "            \n",
    "            # Log significant detections\n",
    "            if results['plates'] or (results['faces'] and \n",
    "                                   any(face['name'] != 'Unknown' for face in results['faces'])):\n",
    "                integrated_system.log_detections(results)\n",
    "                detection_count += 1\n",
    "            \n",
    "            # Draw detections\n",
    "            frame = integrated_system.draw_detections(frame, results)\n",
    "        \n",
    "        # Write frame to output video\n",
    "        if out is not None:\n",
    "            out.write(frame)\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    if out is not None:\n",
    "        out.release()\n",
    "    \n",
    "    print(f\"\\nVideo processing completed!\")\n",
    "    print(f\"Processed {frame_count} frames\")\n",
    "    print(f\"Found {detection_count} significant detections\")\n",
    "    if output_path:\n",
    "        print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "# Example usage (uncomment and modify paths to test):\n",
    "# process_video_file(\"input_video.mp4\", \"output_with_detections.mp4\")\n",
    "\n",
    "print(\"Video processing function ready. Call process_video_file('input.mp4', 'output.mp4') to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccfb27",
   "metadata": {},
   "source": [
    "## 9. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ff9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_detection_results():\n",
    "    \"\"\"View and analyze detection results\"\"\"\n",
    "    csv_filename = \"integrated_results/combined_detections.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"No detection results found.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"=== DETECTION RESULTS ANALYSIS ===\")\n",
    "        print(f\"Total detections: {len(df)}\")\n",
    "        \n",
    "        # Plate statistics\n",
    "        plates_detected = df[df['plate_text'] != ''].shape[0]\n",
    "        unique_plates = df[df['plate_text'] != '']['plate_text'].nunique()\n",
    "        print(f\"\\nLicense Plates:\")\n",
    "        print(f\"  Total detections: {plates_detected}\")\n",
    "        print(f\"  Unique plates: {unique_plates}\")\n",
    "        \n",
    "        if plates_detected > 0:\n",
    "            print(f\"  Average confidence: {df[df['plate_text'] != '']['plate_confidence'].mean():.3f}\")\n",
    "            print(\"\\nMost frequently detected plates:\")\n",
    "            plate_counts = df[df['plate_text'] != '']['plate_text'].value_counts()\n",
    "            for plate, count in plate_counts.head(5).items():\n",
    "                print(f\"    {plate}: {count} times\")\n",
    "        \n",
    "        # Face statistics\n",
    "        faces_detected = df[df['face_name'] != ''].shape[0]\n",
    "        unique_faces = df[df['face_name'] != '']['face_name'].nunique()\n",
    "        print(f\"\\nFaces:\")\n",
    "        print(f\"  Total detections: {faces_detected}\")\n",
    "        print(f\"  Unique faces: {unique_faces}\")\n",
    "        \n",
    "        if faces_detected > 0:\n",
    "            print(f\"  Average confidence: {df[df['face_name'] != '']['face_confidence'].mean():.3f}\")\n",
    "            print(\"\\nMost frequently detected faces:\")\n",
    "            face_counts = df[df['face_name'] != '']['face_name'].value_counts()\n",
    "            for face, count in face_counts.head(5).items():\n",
    "                print(f\"    {face}: {count} times\")\n",
    "        \n",
    "        # Recent detections\n",
    "        print(\"\\n=== RECENT DETECTIONS ===\")\n",
    "        recent = df.tail(10)\n",
    "        for _, row in recent.iterrows():\n",
    "            timestamp = row['timestamp']\n",
    "            plate = row['plate_text'] if row['plate_text'] else \"No plate\"\n",
    "            face = row['face_name'] if row['face_name'] else \"No face\"\n",
    "            print(f\"  {timestamp}: Plate={plate}, Face={face}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading results: {e}\")\n",
    "        return None\n",
    "\n",
    "# View results\n",
    "results_df = view_detection_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a9f6e",
   "metadata": {},
   "source": [
    "## 10. System Configuration and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e86669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System configuration\n",
    "def configure_system():\n",
    "    \"\"\"Configure system parameters\"\"\"\n",
    "    config = {\n",
    "        'anpr': {\n",
    "            'confidence_threshold': 0.5,\n",
    "            'min_plate_width': 100,\n",
    "            'min_plate_height': 30,\n",
    "            'aspect_ratio_min': 2.0,\n",
    "            'aspect_ratio_max': 4.5\n",
    "        },\n",
    "        'frs': {\n",
    "            'recognition_tolerance': 0.6,  # Lower = more strict\n",
    "            'min_face_size': 30\n",
    "        },\n",
    "        'processing': {\n",
    "            'save_detections': True,\n",
    "            'save_unknown_faces': False,\n",
    "            'process_every_nth_frame': 5,\n",
    "            'max_results_to_keep': 1000\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Current system configuration:\")\n",
    "    for category, settings in config.items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        for key, value in settings.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Display current configuration\n",
    "system_config = configure_system()\n",
    "\n",
    "# Function to update face recognition tolerance\n",
    "def set_face_recognition_tolerance(tolerance):\n",
    "    \"\"\"Set face recognition tolerance (0.4 = strict, 0.8 = lenient)\"\"\"\n",
    "    print(f\"Face recognition tolerance set to: {tolerance}\")\n",
    "    print(\"Note: Lower values = more strict matching, Higher values = more lenient\")\n",
    "    return tolerance\n",
    "\n",
    "# Example: set_face_recognition_tolerance(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62709d",
   "metadata": {},
   "source": [
    "## 11. Quick Start Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quick_start_guide():\n",
    "    \"\"\"Print quick start guide\"\"\"\n",
    "    guide = \"\"\"\n",
    "üöÄ QUICK START GUIDE - Indian ANPR + FRS System (TensorFlow-Free)\n",
    "===================================================================\n",
    "\n",
    "1. ADD KNOWN FACES:\n",
    "   - Place face images in 'sample_faces' folder, OR\n",
    "   - Use webcam: capture_and_add_face(\"PersonName\")\n",
    "\n",
    "2. TEST WITH IMAGE:\n",
    "   test_sample_image(\"path/to/your/image.jpg\")\n",
    "\n",
    "3. REAL-TIME DETECTION:\n",
    "   run_realtime_detection()\n",
    "   (Press 'q' to quit)\n",
    "\n",
    "4. PROCESS VIDEO:\n",
    "   process_video_file(\"input.mp4\", \"output.mp4\")\n",
    "\n",
    "5. VIEW RESULTS:\n",
    "   view_detection_results()\n",
    "\n",
    "üìÅ OUTPUT FOLDERS:\n",
    "   - anpr_results/     : License plate detections\n",
    "   - face_results/     : Face recognition results  \n",
    "   - integrated_results/ : Combined ANPR + FRS results\n",
    "   - known_faces/      : Database of known faces\n",
    "\n",
    "üìä FEATURES:\n",
    "   ‚úÖ Indian number plate format detection\n",
    "   ‚úÖ EasyOCR for accurate text extraction\n",
    "   ‚úÖ face_recognition library (no TensorFlow dependency)\n",
    "   ‚úÖ Real-time processing from webcam\n",
    "   ‚úÖ Video file processing\n",
    "   ‚úÖ CSV logging of all detections\n",
    "   ‚úÖ Image saving for verification\n",
    "   ‚úÖ Jupyter notebook visualization\n",
    "\n",
    "üéØ OPTIMIZED FOR:\n",
    "   - Indian vehicle number plates (all formats)\n",
    "   - Multi-language support (Hindi, English)\n",
    "   - Various lighting conditions\n",
    "   - Real-time performance\n",
    "   - Easy installation (no TensorFlow issues)\n",
    "\n",
    "üîß KEY IMPROVEMENTS IN THIS VERSION:\n",
    "   - Replaced TensorFlow/Keras with face_recognition library\n",
    "   - Simplified installation process\n",
    "   - Better error handling\n",
    "   - Improved performance\n",
    "   - Same functionality as TensorFlow version\n",
    "\"\"\"\n",
    "    print(guide)\n",
    "\n",
    "# Display quick start guide\n",
    "print_quick_start_guide()\n",
    "\n",
    "print(\"\\nüéâ SYSTEM READY! üéâ\")\n",
    "print(\"Your TensorFlow-free ANPR + FRS system is now ready to use!\")\n",
    "print(\"Start by adding known faces or test with an image.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
